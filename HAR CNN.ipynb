{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FyOI8iYofNWx"
   },
   "outputs": [],
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 61860,
     "status": "ok",
     "timestamp": 1584248132952,
     "user": {
      "displayName": "Himanshu Katarwar",
      "photoUrl": "",
      "userId": "18404176375943820148"
     },
     "user_tz": -330
    },
    "id": "JrWcj335hLIx",
    "outputId": "e165bd28-67d2-4bbb-ee0c-aee7e3c1f21a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IhpdizLJfNW2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "06zEZ2h9fNW6"
   },
   "outputs": [],
   "source": [
    "# Activities are the class labels\n",
    "# It is a 6 class classification\n",
    "ACTIVITIES = {\n",
    "    0: 'WALKING',\n",
    "    1: 'WALKING_UPSTAIRS',\n",
    "    2: 'WALKING_DOWNSTAIRS',\n",
    "    3: 'SITTING',\n",
    "    4: 'STANDING',\n",
    "    5: 'LAYING',\n",
    "}\n",
    "\n",
    "# Utility function to print the confusion matrix\n",
    "def confusion_matrix(Y_true, Y_pred):\n",
    "    Y_true = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_true, axis=1)])\n",
    "    Y_pred = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_pred, axis=1)])\n",
    "\n",
    "    return pd.crosstab(Y_true, Y_pred, rownames=['True'], colnames=['Pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f1dp5JzzfNW9"
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VS5-eO5YfNW-"
   },
   "outputs": [],
   "source": [
    "# Data directory\n",
    "DATADIR = '/content/drive/My Drive/UCI_HAR_Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YQ7N9Oe5fNXB"
   },
   "outputs": [],
   "source": [
    "# Raw data signals\n",
    "# Signals are from Accelerometer and Gyroscope\n",
    "# The signals are in x,y,z directions\n",
    "# Sensor signals are filtered to have only body acceleration\n",
    "# excluding the acceleration due to gravity\n",
    "# Triaxial acceleration from the accelerometer is total acceleration\n",
    "SIGNALS = [\n",
    "    \"body_acc_x\",\n",
    "    \"body_acc_y\",\n",
    "    \"body_acc_z\",\n",
    "    \"body_gyro_x\",\n",
    "    \"body_gyro_y\",\n",
    "    \"body_gyro_z\",\n",
    "    \"total_acc_x\",\n",
    "    \"total_acc_y\",\n",
    "    \"total_acc_z\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1261,
     "status": "ok",
     "timestamp": 1582345636625,
     "user": {
      "displayName": "Himanshu Katarwar",
      "photoUrl": "",
      "userId": "18404176375943820148"
     },
     "user_tz": -330
    },
    "id": "_0Xb2-e7JFQw",
    "outputId": "95bbcc8a-4e99-4b96-cfbf-d4f0171048b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0\n",
      "0     1\n",
      "1     1\n",
      "2     1\n",
      "3     1\n",
      "4     1\n",
      "...  ..\n",
      "7347  0\n",
      "7348  0\n",
      "7349  0\n",
      "7350  0\n",
      "7351  0\n",
      "\n",
      "[7352 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "filename = f'/content/drive/My Drive/UCI_HAR_Dataset/train/y_train.txt'\n",
    "y=pd.read_csv(filename, delim_whitespace=True, header=None)\n",
    "y[y<=3] = 0\n",
    "y[y>3] = 1\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ilHjLxQjfNXE"
   },
   "outputs": [],
   "source": [
    "# Utility function to read the data from csv file\n",
    "def _read_csv(filename):\n",
    "    return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
    "\n",
    "# Utility function to load the load\n",
    "def load_signals(subset):\n",
    "    signals_data = []\n",
    "\n",
    "    for signal in SIGNALS:\n",
    "        filename = f'/content/drive/My Drive/UCI_HAR_Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
    "        signals_data.append(\n",
    "            _read_csv(filename).as_matrix()\n",
    "        ) \n",
    "\n",
    "    # Transpose is used to change the dimensionality of the output,\n",
    "    # aggregating the signals by combination of sample/timestep.\n",
    "    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
    "    return np.transpose(signals_data, (1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UhuuTOzsfNXI"
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_y(subset):\n",
    "    \"\"\"\n",
    "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
    "    that represents a human activity. We return a binary representation of \n",
    "    every sample objective as a 6 bits vector using One Hot Encoding\n",
    "    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
    "    \"\"\"\n",
    "    filename = f'/content/drive/My Drive/UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
    "    y = _read_csv(filename)[0]\n",
    "\n",
    "    return pd.get_dummies(y).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lBIh3BUxfNXL"
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    Obtain the dataset from multiple files.\n",
    "    Returns: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    X_train, X_test = load_signals('train'), load_signals('test')\n",
    "    y_train, y_test = load_y('train'), load_y('test')\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 62
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3098,
     "status": "ok",
     "timestamp": 1582256437669,
     "user": {
      "displayName": "Himanshu Katarwar",
      "photoUrl": "",
      "userId": "18404176375943820148"
     },
     "user_tz": -330
    },
    "id": "LfL2tbZbfNXO",
    "outputId": "b1fabfcd-cde1-4907-9fee-8d76c0be1a52"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importing tensorflow\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1kJ3ECX9fNXS"
   },
   "outputs": [],
   "source": [
    "# Configuring a session\n",
    "session_conf = tf.ConfigProto(\n",
    "    intra_op_parallelism_threads=1,\n",
    "    inter_op_parallelism_threads=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1365,
     "status": "ok",
     "timestamp": 1582169478830,
     "user": {
      "displayName": "Himanshu Katarwar",
      "photoUrl": "",
      "userId": "18404176375943820148"
     },
     "user_tz": -330
    },
    "id": "p9Rj1sJ-fNXV",
    "outputId": "6c99da82-4c61-407e-df52-b500f2bf8479"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import Keras\n",
    "from keras import backend as K\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4527,
     "status": "ok",
     "timestamp": 1584248133327,
     "user": {
      "displayName": "Himanshu Katarwar",
      "photoUrl": "",
      "userId": "18404176375943820148"
     },
     "user_tz": -330
    },
    "id": "6BMMaL6xfNXY",
    "outputId": "2ac55c7a-d1cd-4193-c090-a70c536eff98"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importing libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Bidirectional\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras import regularizers\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import Input, Dense,TimeDistributed\n",
    "from keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1AFwG2yMfNXb"
   },
   "outputs": [],
   "source": [
    "# Initializing parameters\n",
    "epochs = 30\n",
    "batch_size = 16\n",
    "n_hidden = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ad6Zc_hYfNXd"
   },
   "outputs": [],
   "source": [
    "# Utility function to count the number of classes\n",
    "def _count_classes(y):\n",
    "    return len(set([tuple(category) for category in y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I74kpqO8fNXh"
   },
   "outputs": [],
   "source": [
    "# Loading the train and test data\n",
    "X_train, X_test, Y_train, Y_test = load_data()\n",
    "np.save(\"/content/drive/My Drive/train\", X_train)\n",
    "np.save(\"/content/drive/My Drive/train_label\", Y_train)\n",
    "np.save(\"/content/drive/My Drive/test\", X_test)\n",
    "np.save(\"/content/drive/My Drive/test_label\", Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TE-PCKt1b8UI"
   },
   "outputs": [],
   "source": [
    "def data():\n",
    "    x_train = np.load(\"/content/drive/My Drive/train.npy\")\n",
    "    y_train = np.load(\"/content/drive/My Drive/train_label.npy\")\n",
    "    x_test = np.load(\"/content/drive/My Drive/test.npy\")\n",
    "    y_test = np.load(\"/content/drive/My Drive/test_label.npy\")\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3545,
     "status": "ok",
     "timestamp": 1582170180853,
     "user": {
      "displayName": "Himanshu Katarwar",
      "photoUrl": "",
      "userId": "18404176375943820148"
     },
     "user_tz": -330
    },
    "id": "toTUCgXjfNXk",
    "outputId": "69f86966-3d17-4d4f-8887-98b0e722a97f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "9\n",
      "7352\n"
     ]
    }
   ],
   "source": [
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = _count_classes(Y_train)\n",
    "\n",
    "print(timesteps)\n",
    "print(input_dim)\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pwqR4pH4fNXp"
   },
   "source": [
    "- Defining the Architecture of LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TZS1ZMAVFFjE"
   },
   "outputs": [],
   "source": [
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q_sX5yz5_IDQ"
   },
   "source": [
    "# CNN1D LSTM  MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hXqJ3Tn-XWOF"
   },
   "outputs": [],
   "source": [
    "def data():\n",
    "  class scaling_tseries_data():\n",
    "    def __init__(self):\n",
    "      self.scale = None\n",
    "\n",
    "    def transform(self, X):\n",
    "      temp_X1 = X.reshape((X.shape[0] * X.shape[1], X.shape[2]))\n",
    "      temp_X1 = self.scale.transform(temp_X1)\n",
    "      return temp_X1.reshape(X.shape)\n",
    "\n",
    "    def fit(self, X):\n",
    "      remove = int(X.shape[1] / 2)\n",
    "      temp_X = X[:, -remove:, :]\n",
    "      # flatten data\n",
    "      temp_X = temp_X.reshape((temp_X.shape[0] * temp_X.shape[1], temp_X.shape[2]))\n",
    "      scale = StandardScaler()\n",
    "      scale.fit(temp_X)\n",
    "      self.scale = scale\n",
    "      return self\n",
    "  def _read_csv(filename):\n",
    "      return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
    "\n",
    "  def load_y(subset):\n",
    "    filename = f'/content/drive/My Drive/UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
    "    y = _read_csv(filename)[0]\n",
    "    return pd.get_dummies(y).as_matrix()\n",
    "  def load_signals(subset):\n",
    "    signals_data = []\n",
    "\n",
    "    for signal in [\n",
    "    \"body_acc_x\",\n",
    "    \"body_acc_y\",\n",
    "    \"body_acc_z\",\n",
    "    \"body_gyro_x\",\n",
    "    \"body_gyro_y\",\n",
    "    \"body_gyro_z\",\n",
    "    \"total_acc_x\",\n",
    "    \"total_acc_y\",\n",
    "    \"total_acc_z\"]:\n",
    "      filename = f'/content/drive/My Drive/UCI_HAR_Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
    "      signals_data.append(_read_csv(filename).as_matrix()) \n",
    "    # Transpose is used to change the dimensionality of the output,\n",
    "    # aggregating the signals by combination of sample/timestep.\n",
    "    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
    "    return np.transpose(signals_data, (1, 2, 0))\n",
    "\n",
    "  X_train_d,X_val_d=load_signals('train'),load_signals('test')\n",
    "  Y_train_d,Y_val_d = load_y('train'), load_y('test')\n",
    "\n",
    "  Scale = scaling_tseries_data()\n",
    "  Scale.fit(X_train_d)\n",
    "  X_train_d = Scale.transform(X_train_d)\n",
    "  X_val_d = Scale.transform(X_val_d)\n",
    "  n_timestamps,n_features=X_train_d.shape[1],X_train_d.shape[2]\n",
    "  n_steps,n_length=4,32\n",
    "  X_train_d=X_train_d.reshape((X_train_d.shape[0],n_steps,n_length,n_features))\n",
    "  X_val_d=X_val_d.reshape((X_val_d.shape[0],n_steps,n_length,n_features))\n",
    "\n",
    "  return X_train_d, Y_train_d, X_val_d, Y_val_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5WDOkvh3oXUk"
   },
   "outputs": [],
   "source": [
    "X_train_d, Y_train_d, X_val_d,  Y_val_d = data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 19700,
     "status": "ok",
     "timestamp": 1584248208247,
     "user": {
      "displayName": "Himanshu Katarwar",
      "photoUrl": "",
      "userId": "18404176375943820148"
     },
     "user_tz": -330
    },
    "id": "jDHiSuqQozlv",
    "outputId": "a9ce3327-e169-492f-b29f-e872b3eef68d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X shape (7352, 4, 32, 9) Test X shape (2947, 4, 32, 9)\n",
      "Train True_Y shape (7352, 6) Test True_Y shape (2947, 6)\n"
     ]
    }
   ],
   "source": [
    "print('Train X shape',X_train_d.shape,'Test X shape',X_val_d.shape)\n",
    "print('Train True_Y shape',Y_train_d.shape,'Test True_Y shape',Y_val_d.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mS4OQHvm0Eaf"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D,MaxPooling1D,Flatten,LSTM\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2bsvY-a106i5"
   },
   "outputs": [],
   "source": [
    "#https://machinelearningmastery.com/how-to-develop-rnn-models-for-human-activity-recognition-time-series-classification/\n",
    "def MODEL(X_train_d,Y_train_d,X_val_d,Y_val_d):\n",
    "\n",
    "  model=Sequential()\n",
    "  model.add(TimeDistributed(Conv1D(filters=72,kernel_size=4,activation='relu',kernel_regularizer=regularizers.l2({{uniform(0.000000001,0.000001)}})),input_shape=(None,32,9)))\n",
    "\n",
    "  model.add(TimeDistributed(Conv1D(filters=32,kernel_size=3,activation='relu',kernel_regularizer=regularizers.l2({{uniform(0.0000000001,0.00001)}}))))\n",
    "  model.add(TimeDistributed(Dropout({{uniform(0.2,1)}})))\n",
    "  model.add(TimeDistributed(MaxPooling1D(pool_size={{choice([2,4,5,7,9,8,3,6])}})))\n",
    "  model.add(TimeDistributed(Flatten()))\n",
    "  model.add(LSTM(170,kernel_regularizer=regularizers.l2({{uniform(0.000000001,0.000001)}})))\n",
    "  model.add(Dropout({{uniform(0.6,1)}}))\n",
    "  model.add(Dense(64,activation='relu',kernel_regularizer=regularizers.l2({{uniform(0.000000001,0.000001)}})))\n",
    "  model.add(Dense(6,activation='softmax'))\n",
    "  adam = keras.optimizers.Adam(lr={{uniform(0.00065,0.004)}})\n",
    "\n",
    "  print(model.summary())\n",
    "      \n",
    "  model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer=adam)\n",
    "  \n",
    "  result = model.fit(X_train_d, Y_train_d,\n",
    "            batch_size=16,\n",
    "            nb_epoch=40,\n",
    "            verbose=2,\n",
    "            validation_data=(X_val_d, Y_val_d))\n",
    "                      \n",
    "  score, acc = model.evaluate(X_val_d, Y_val_d, verbose=0)\n",
    "  score1, acc1 = model.evaluate(X_train_d, Y_train_d, verbose=0)\n",
    "  print('Train accuracy',acc1,'Test accuracy:', acc)\n",
    "  print('-------------------------------------------------------------------------------------')\n",
    "  \n",
    "  return {'loss': -acc, 'status': STATUS_OK,'train_acc':acc1,'model':model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5049585,
     "status": "ok",
     "timestamp": 1584267260496,
     "user": {
      "displayName": "Himanshu Katarwar",
      "photoUrl": "",
      "userId": "18404176375943820148"
     },
     "user_tz": -330
    },
    "id": "GKHZdoQRFCBG",
    "outputId": "d22c4eb1-fd17-4844-f856-89a641592344"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    from google.colab import drive\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pickle\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import tensorflow as tf\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend as K\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import LSTM, Bidirectional\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.core import Dense, Dropout\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import regularizers\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Conv1D\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Input, Dense, TimeDistributed\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Model\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Conv1D, MaxPooling1D, Flatten, LSTM\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import keras\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import matplotlib.pyplot as plt\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'l2': hp.uniform('l2', 0.000000001,0.000001),\n",
      "        'l2_1': hp.uniform('l2_1', 0.0000000001,0.00001),\n",
      "        'Dropout': hp.uniform('Dropout', 0.2,1),\n",
      "        'pool_size': hp.choice('pool_size', [2,4,5,7,9,8,3,6]),\n",
      "        'l2_2': hp.uniform('l2_2', 0.000000001,0.000001),\n",
      "        'Dropout_1': hp.uniform('Dropout_1', 0.6,1),\n",
      "        'l2_3': hp.uniform('l2_3', 0.000000001,0.000001),\n",
      "        'lr': hp.uniform('lr', 0.00065,0.004),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "   1: \n",
      "   2: class scaling_tseries_data():\n",
      "   3:   def __init__(self):\n",
      "   4:     self.scale = None\n",
      "   5: \n",
      "   6:   def transform(self, X):\n",
      "   7:     temp_X1 = X.reshape((X.shape[0] * X.shape[1], X.shape[2]))\n",
      "   8:     temp_X1 = self.scale.transform(temp_X1)\n",
      "   9:     return temp_X1.reshape(X.shape)\n",
      "  10: \n",
      "  11:   def fit(self, X):\n",
      "  12:     remove = int(X.shape[1] / 2)\n",
      "  13:     temp_X = X[:, -remove:, :]\n",
      "  14:     # flatten data\n",
      "  15:     temp_X = temp_X.reshape((temp_X.shape[0] * temp_X.shape[1], temp_X.shape[2]))\n",
      "  16:     scale = StandardScaler()\n",
      "  17:     scale.fit(temp_X)\n",
      "  18:     pickle.dump(scale,open('/content/drive/My Drive/scale_2class.p','wb'))\n",
      "  19:     self.scale = scale\n",
      "  20:     return self\n",
      "  21: def _read_csv(filename):\n",
      "  22:     return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
      "  23: \n",
      "  24: \n",
      "  25: def load_y(subset):\n",
      "  26:   \"\"\"\n",
      "  27:   The objective that we are trying to predict is a integer, from 1 to 6,\n",
      "  28:   that represents a human activity. We return a binary representation of \n",
      "  29:   every sample objective as a 6 bits vector using One Hot Encoding\n",
      "  30:   (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
      "  31:   \"\"\"\n",
      "  32:   filename = f'/content/drive/My Drive/UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
      "  33:   y = _read_csv(filename)[0]\n",
      "  34:   return pd.get_dummies(y).as_matrix()\n",
      "  35: def load_signals(subset):\n",
      "  36:   signals_data = []\n",
      "  37: \n",
      "  38:   for signal in [\n",
      "  39:   \"body_acc_x\",\n",
      "  40:   \"body_acc_y\",\n",
      "  41:   \"body_acc_z\",\n",
      "  42:   \"body_gyro_x\",\n",
      "  43:   \"body_gyro_y\",\n",
      "  44:   \"body_gyro_z\",\n",
      "  45:   \"total_acc_x\",\n",
      "  46:   \"total_acc_y\",\n",
      "  47:   \"total_acc_z\"]:\n",
      "  48:     filename = f'/content/drive/My Drive/UCI_HAR_Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
      "  49:     signals_data.append(_read_csv(filename).as_matrix()) \n",
      "  50:   # Transpose is used to change the dimensionality of the output,\n",
      "  51:   # aggregating the signals by combination of sample/timestep.\n",
      "  52:   # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
      "  53:   return np.transpose(signals_data, (1, 2, 0))\n",
      "  54: \n",
      "  55: X_train_d,X_val_d=load_signals('train'),load_signals('test')\n",
      "  56: Y_train_d,Y_val_d = load_y('train'), load_y('test')\n",
      "  57: \n",
      "  58: Scale = scaling_tseries_data()\n",
      "  59: Scale.fit(X_train_d)\n",
      "  60: X_train_d = Scale.transform(X_train_d)\n",
      "  61: X_val_d = Scale.transform(X_val_d)\n",
      "  62: n_timestamps,n_features=X_train_d.shape[1],X_train_d.shape[2]\n",
      "  63: n_steps,n_length=4,32\n",
      "  64: X_train_d=X_train_d.reshape((X_train_d.shape[0],n_steps,n_length,n_features))\n",
      "  65: X_val_d=X_val_d.reshape((X_val_d.shape[0],n_steps,n_length,n_features))\n",
      "  66: \n",
      "  67: \n",
      "  68: \n",
      "  69: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3: \n",
      "   4:   model=Sequential()\n",
      "   5:   model.add(TimeDistributed(Conv1D(filters=72,kernel_size=4,activation='relu',kernel_regularizer=regularizers.l2(space['l2'])),input_shape=(None,32,9)))\n",
      "   6: \n",
      "   7:   model.add(TimeDistributed(Conv1D(filters=32,kernel_size=3,activation='relu',kernel_regularizer=regularizers.l2(space['l2_1']))))\n",
      "   8:   model.add(TimeDistributed(Dropout(space['Dropout'])))\n",
      "   9:   model.add(TimeDistributed(MaxPooling1D(pool_size=space['pool_size'])))\n",
      "  10:   model.add(TimeDistributed(Flatten()))\n",
      "  11:   model.add(LSTM(170,kernel_regularizer=regularizers.l2(space['l2_2'])))\n",
      "  12:   model.add(Dropout(space['Dropout_1']))\n",
      "  13:   model.add(Dense(64,activation='relu',kernel_regularizer=regularizers.l2(space['l2_3'])))\n",
      "  14:   model.add(Dense(6,activation='softmax'))\n",
      "  15:   adam = keras.optimizers.Adam(lr=space['lr'])\n",
      "  16: \n",
      "  17:   print(model.summary())\n",
      "  18:       \n",
      "  19:   model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer=adam)\n",
      "  20:   \n",
      "  21:   result = model.fit(X_train_d, Y_train_d,\n",
      "  22:             batch_size=16,\n",
      "  23:             nb_epoch=40,\n",
      "  24:             verbose=2,\n",
      "  25:             validation_data=(X_val_d, Y_val_d))\n",
      "  26:                       \n",
      "  27:   score, acc = model.evaluate(X_val_d, Y_val_d, verbose=0)\n",
      "  28:   score1, acc1 = model.evaluate(X_train_d, Y_train_d, verbose=0)\n",
      "  29:   print('Train accuracy',acc1,'Test accuracy:', acc)\n",
      "  30:   print('-------------------------------------------------------------------------------------')\n",
      "  31:   \n",
      "  32:   return {'loss': -acc, 'status': STATUS_OK,'train_acc':acc1,'model':model}\n",
      "  33: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/hyperas/utils.py:149: UserWarning: Inconsistent indentation detected.Found \"  \" (length: 2) as well as \"    \" (length: 4)\n",
      "  indent, len(indent), new_indent, len(new_indent)))\n",
      "/usr/local/lib/python3.6/dist-packages/hyperas/utils.py:149: UserWarning: Inconsistent indentation detected.Found \"    \" (length: 4) as well as \"  \" (length: 2)\n",
      "  indent, len(indent), new_indent, len(new_indent)))\n",
      "/content/temp_model.py:151: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  signals_data.append(_read_csv(filename).as_matrix())\n",
      "/content/temp_model.py:136: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  return pd.get_dummies(y).as_matrix()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_132 (TimeDi (None, None, 29, 72)      2664      \n",
      "_________________________________________________________________\n",
      "time_distributed_133 (TimeDi (None, None, 27, 32)      6944      \n",
      "_________________________________________________________________\n",
      "time_distributed_134 (TimeDi (None, None, 27, 32)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_135 (TimeDi (None, None, 9, 32)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed_136 (TimeDi (None, None, 288)         0         \n",
      "_________________________________________________________________\n",
      "lstm_26 (LSTM)               (None, 170)               312120    \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 64)                10944     \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 333,062\n",
      "Trainable params: 333,062\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "  0%|          | 0/10 [00:00<?, ?it/s, best loss: ?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/temp_model.py:195: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  validation_data=(X_val_d, Y_val_d))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/40\n",
      " - 24s - loss: 0.3696 - acc: 0.8460 - val_loss: 0.2979 - val_acc: 0.9019\n",
      "\n",
      "Epoch 2/40\n",
      " - 14s - loss: 0.1357 - acc: 0.9482 - val_loss: 0.2157 - val_acc: 0.9182\n",
      "\n",
      "Epoch 3/40\n",
      " - 15s - loss: 0.1197 - acc: 0.9490 - val_loss: 0.2262 - val_acc: 0.9243\n",
      "\n",
      "Epoch 4/40\n",
      " - 15s - loss: 0.1182 - acc: 0.9514 - val_loss: 0.2322 - val_acc: 0.9196\n",
      "\n",
      "Epoch 5/40\n",
      " - 16s - loss: 0.1125 - acc: 0.9529 - val_loss: 0.2304 - val_acc: 0.9253\n",
      "\n",
      "Epoch 6/40\n",
      " - 15s - loss: 0.0897 - acc: 0.9596 - val_loss: 0.4063 - val_acc: 0.8897\n",
      "\n",
      "Epoch 7/40\n",
      " - 15s - loss: 0.0946 - acc: 0.9577 - val_loss: 0.2651 - val_acc: 0.9335\n",
      "\n",
      "Epoch 8/40\n",
      " - 15s - loss: 0.0833 - acc: 0.9623 - val_loss: 0.2821 - val_acc: 0.9270\n",
      "\n",
      "Epoch 9/40\n",
      " - 15s - loss: 0.0914 - acc: 0.9611 - val_loss: 0.2692 - val_acc: 0.9060\n",
      "\n",
      "Epoch 10/40\n",
      " - 15s - loss: 0.1017 - acc: 0.9572 - val_loss: 0.3370 - val_acc: 0.9264\n",
      "\n",
      "Epoch 11/40\n",
      " - 15s - loss: 0.0868 - acc: 0.9653 - val_loss: 0.2436 - val_acc: 0.9247\n",
      "\n",
      "Epoch 12/40\n",
      " - 15s - loss: 0.0746 - acc: 0.9655 - val_loss: 0.2864 - val_acc: 0.9284\n",
      "\n",
      "Epoch 13/40\n",
      " - 15s - loss: 0.0855 - acc: 0.9601 - val_loss: 0.3171 - val_acc: 0.9175\n",
      "\n",
      "Epoch 14/40\n",
      " - 15s - loss: 0.0745 - acc: 0.9664 - val_loss: 0.3066 - val_acc: 0.9216\n",
      "\n",
      "Epoch 15/40\n",
      " - 16s - loss: 0.0676 - acc: 0.9698 - val_loss: 0.3584 - val_acc: 0.9175\n",
      "\n",
      "Epoch 16/40\n",
      " - 15s - loss: 0.0882 - acc: 0.9638 - val_loss: 0.3058 - val_acc: 0.9209\n",
      "\n",
      "Epoch 17/40\n",
      " - 15s - loss: 0.0687 - acc: 0.9694 - val_loss: 0.2941 - val_acc: 0.9301\n",
      "\n",
      "Epoch 18/40\n",
      " - 15s - loss: 0.0580 - acc: 0.9731 - val_loss: 0.3121 - val_acc: 0.9311\n",
      "\n",
      "Epoch 19/40\n",
      " - 15s - loss: 0.0603 - acc: 0.9710 - val_loss: 0.3073 - val_acc: 0.9294\n",
      "\n",
      "Epoch 20/40\n",
      " - 15s - loss: 0.0606 - acc: 0.9757 - val_loss: 0.3111 - val_acc: 0.9155\n",
      "\n",
      "Epoch 21/40\n",
      " - 15s - loss: 0.0586 - acc: 0.9725 - val_loss: 0.3200 - val_acc: 0.9250\n",
      "\n",
      "Epoch 22/40\n",
      " - 16s - loss: 0.0562 - acc: 0.9755 - val_loss: 0.2808 - val_acc: 0.9131\n",
      "\n",
      "Epoch 23/40\n",
      " - 15s - loss: 0.0572 - acc: 0.9746 - val_loss: 0.3067 - val_acc: 0.9125\n",
      "\n",
      "Epoch 24/40\n",
      " - 15s - loss: 0.0739 - acc: 0.9720 - val_loss: 0.3417 - val_acc: 0.9247\n",
      "\n",
      "Epoch 25/40\n",
      " - 16s - loss: 0.0513 - acc: 0.9796 - val_loss: 0.3824 - val_acc: 0.9267\n",
      "\n",
      "Epoch 26/40\n",
      " - 15s - loss: 0.0474 - acc: 0.9777 - val_loss: 0.4456 - val_acc: 0.9253\n",
      "\n",
      "Epoch 27/40\n",
      " - 15s - loss: 0.0542 - acc: 0.9758 - val_loss: 0.3504 - val_acc: 0.9257\n",
      "\n",
      "Epoch 28/40\n",
      " - 15s - loss: 0.0506 - acc: 0.9780 - val_loss: 0.4067 - val_acc: 0.9260\n",
      "\n",
      "Epoch 29/40\n",
      " - 15s - loss: 0.0591 - acc: 0.9762 - val_loss: 0.3741 - val_acc: 0.9165\n",
      "\n",
      "Epoch 30/40\n",
      " - 15s - loss: 0.0544 - acc: 0.9776 - val_loss: 0.3510 - val_acc: 0.9192\n",
      "\n",
      "Epoch 31/40\n",
      " - 15s - loss: 0.0688 - acc: 0.9762 - val_loss: 0.3510 - val_acc: 0.9158\n",
      "\n",
      "Epoch 32/40\n",
      " - 15s - loss: 0.0479 - acc: 0.9786 - val_loss: 0.3320 - val_acc: 0.9328\n",
      "\n",
      "Epoch 33/40\n",
      " - 15s - loss: 0.0577 - acc: 0.9774 - val_loss: 0.4167 - val_acc: 0.9209\n",
      "\n",
      "Epoch 34/40\n",
      " - 15s - loss: 0.0470 - acc: 0.9814 - val_loss: 0.4521 - val_acc: 0.9274\n",
      "\n",
      "Epoch 35/40\n",
      " - 15s - loss: 0.0519 - acc: 0.9791 - val_loss: 0.4573 - val_acc: 0.9216\n",
      "\n",
      "Epoch 36/40\n",
      " - 16s - loss: 0.0513 - acc: 0.9781 - val_loss: 0.4660 - val_acc: 0.9145\n",
      "\n",
      "Epoch 37/40\n",
      " - 15s - loss: 0.0403 - acc: 0.9834 - val_loss: 0.4255 - val_acc: 0.9172\n",
      "\n",
      "Epoch 38/40\n",
      " - 15s - loss: 0.0391 - acc: 0.9839 - val_loss: 0.4429 - val_acc: 0.9199\n",
      "\n",
      "Epoch 39/40\n",
      " - 15s - loss: 0.0579 - acc: 0.9827 - val_loss: 0.3563 - val_acc: 0.9247\n",
      "\n",
      "Epoch 40/40\n",
      " - 15s - loss: 0.0717 - acc: 0.9762 - val_loss: 0.4091 - val_acc: 0.9226\n",
      "\n",
      "Train accuracy\n",
      "0.9870783460282916\n",
      "Test accuracy:\n",
      "0.9226331862911435\n",
      "-------------------------------------------------------------------------------------\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_137 (TimeDi (None, None, 29, 72)      2664      \n",
      "_________________________________________________________________\n",
      "time_distributed_138 (TimeDi (None, None, 27, 32)      6944      \n",
      "_________________________________________________________________\n",
      "time_distributed_139 (TimeDi (None, None, 27, 32)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_140 (TimeDi (None, None, 3, 32)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed_141 (TimeDi (None, None, 96)          0         \n",
      "_________________________________________________________________\n",
      "lstm_27 (LSTM)               (None, 170)               181560    \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 64)                10944     \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 202,502\n",
      "Trainable params: 202,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      " 10%|█         | 1/10 [10:22<1:33:20, 622.30s/it, best loss: -0.9226331862911435]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/temp_model.py:195: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  validation_data=(X_val_d, Y_val_d))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/40\n",
      " - 23s - loss: 0.4686 - acc: 0.8200 - val_loss: 0.1985 - val_acc: 0.9189\n",
      "\n",
      "Epoch 2/40\n",
      " - 12s - loss: 0.1621 - acc: 0.9403 - val_loss: 0.2260 - val_acc: 0.9057\n",
      "\n",
      "Epoch 3/40\n",
      " - 12s - loss: 0.1376 - acc: 0.9484 - val_loss: 0.2378 - val_acc: 0.9175\n",
      "\n",
      "Epoch 4/40\n",
      " - 12s - loss: 0.1192 - acc: 0.9524 - val_loss: 0.2359 - val_acc: 0.9237\n",
      "\n",
      "Epoch 5/40\n",
      " - 12s - loss: 0.1343 - acc: 0.9493 - val_loss: 0.2326 - val_acc: 0.9291\n",
      "\n",
      "Epoch 6/40\n",
      " - 12s - loss: 0.1259 - acc: 0.9529 - val_loss: 0.2979 - val_acc: 0.9223\n",
      "\n",
      "Epoch 7/40\n",
      " - 12s - loss: 0.1125 - acc: 0.9577 - val_loss: 0.2459 - val_acc: 0.9230\n",
      "\n",
      "Epoch 8/40\n",
      " - 12s - loss: 0.1016 - acc: 0.9585 - val_loss: 0.2100 - val_acc: 0.9257\n",
      "\n",
      "Epoch 9/40\n",
      " - 12s - loss: 0.1062 - acc: 0.9585 - val_loss: 0.2947 - val_acc: 0.9352\n",
      "\n",
      "Epoch 10/40\n",
      " - 12s - loss: 0.0888 - acc: 0.9664 - val_loss: 0.2905 - val_acc: 0.9294\n",
      "\n",
      "Epoch 11/40\n",
      " - 12s - loss: 0.0915 - acc: 0.9634 - val_loss: 0.2837 - val_acc: 0.9321\n",
      "\n",
      "Epoch 12/40\n",
      " - 12s - loss: 0.0764 - acc: 0.9693 - val_loss: 0.2766 - val_acc: 0.9362\n",
      "\n",
      "Epoch 13/40\n",
      " - 12s - loss: 0.0893 - acc: 0.9656 - val_loss: 0.3362 - val_acc: 0.9223\n",
      "\n",
      "Epoch 14/40\n",
      " - 12s - loss: 0.0771 - acc: 0.9693 - val_loss: 0.3094 - val_acc: 0.9369\n",
      "\n",
      "Epoch 15/40\n",
      " - 12s - loss: 0.0669 - acc: 0.9689 - val_loss: 0.3678 - val_acc: 0.9114\n",
      "\n",
      "Epoch 16/40\n",
      " - 12s - loss: 0.0817 - acc: 0.9712 - val_loss: 0.3527 - val_acc: 0.9369\n",
      "\n",
      "Epoch 17/40\n",
      " - 12s - loss: 0.0569 - acc: 0.9755 - val_loss: 0.4021 - val_acc: 0.9328\n",
      "\n",
      "Epoch 18/40\n",
      " - 12s - loss: 0.0541 - acc: 0.9769 - val_loss: 0.4515 - val_acc: 0.9376\n",
      "\n",
      "Epoch 19/40\n",
      " - 12s - loss: 0.0608 - acc: 0.9757 - val_loss: 0.4241 - val_acc: 0.9318\n",
      "\n",
      "Epoch 20/40\n",
      " - 12s - loss: 0.0715 - acc: 0.9724 - val_loss: 0.4536 - val_acc: 0.9240\n",
      "\n",
      "Epoch 21/40\n",
      " - 12s - loss: 0.1085 - acc: 0.9668 - val_loss: 0.3705 - val_acc: 0.9430\n",
      "\n",
      "Epoch 22/40\n",
      " - 12s - loss: 0.0623 - acc: 0.9780 - val_loss: 0.4344 - val_acc: 0.9423\n",
      "\n",
      "Epoch 23/40\n",
      " - 12s - loss: 0.0734 - acc: 0.9728 - val_loss: 0.3281 - val_acc: 0.9437\n",
      "\n",
      "Epoch 24/40\n",
      " - 12s - loss: 0.0652 - acc: 0.9771 - val_loss: 0.3920 - val_acc: 0.9267\n",
      "\n",
      "Epoch 25/40\n",
      " - 12s - loss: 0.0852 - acc: 0.9709 - val_loss: 0.3434 - val_acc: 0.9471\n",
      "\n",
      "Epoch 26/40\n",
      " - 12s - loss: 0.0539 - acc: 0.9786 - val_loss: 0.3876 - val_acc: 0.9464\n",
      "\n",
      "Epoch 27/40\n",
      " - 12s - loss: 0.0529 - acc: 0.9780 - val_loss: 0.4190 - val_acc: 0.9389\n",
      "\n",
      "Epoch 28/40\n",
      " - 12s - loss: 0.0514 - acc: 0.9791 - val_loss: 0.4368 - val_acc: 0.9450\n",
      "\n",
      "Epoch 29/40\n",
      " - 12s - loss: 0.0419 - acc: 0.9831 - val_loss: 0.4219 - val_acc: 0.9325\n",
      "\n",
      "Epoch 30/40\n",
      " - 12s - loss: 0.0564 - acc: 0.9826 - val_loss: 0.3697 - val_acc: 0.9454\n",
      "\n",
      "Epoch 31/40\n",
      " - 12s - loss: 0.0582 - acc: 0.9822 - val_loss: 0.3592 - val_acc: 0.9399\n",
      "\n",
      "Epoch 32/40\n",
      " - 12s - loss: 0.0705 - acc: 0.9762 - val_loss: 0.4264 - val_acc: 0.9399\n",
      "\n",
      "Epoch 33/40\n",
      " - 12s - loss: 0.0688 - acc: 0.9789 - val_loss: 0.3514 - val_acc: 0.9315\n",
      "\n",
      "Epoch 34/40\n",
      " - 12s - loss: 0.0449 - acc: 0.9827 - val_loss: 0.3964 - val_acc: 0.9284\n",
      "\n",
      "Epoch 35/40\n",
      " - 12s - loss: 0.0390 - acc: 0.9856 - val_loss: 0.4554 - val_acc: 0.9318\n",
      "\n",
      "Epoch 36/40\n",
      " - 12s - loss: 0.0482 - acc: 0.9842 - val_loss: 0.3182 - val_acc: 0.9403\n",
      "\n",
      "Epoch 37/40\n",
      " - 12s - loss: 0.0432 - acc: 0.9845 - val_loss: 0.3744 - val_acc: 0.9386\n",
      "\n",
      "Epoch 38/40\n",
      " - 12s - loss: 0.0461 - acc: 0.9837 - val_loss: 0.3963 - val_acc: 0.9389\n",
      "\n",
      "Epoch 39/40\n",
      " - 12s - loss: 0.0560 - acc: 0.9814 - val_loss: 0.4365 - val_acc: 0.9430\n",
      "\n",
      "Epoch 40/40\n",
      " - 12s - loss: 0.0339 - acc: 0.9880 - val_loss: 0.4289 - val_acc: 0.9437\n",
      "\n",
      "Train accuracy\n",
      "0.9876224156692056\n",
      "Test accuracy:\n",
      "0.9436715303698676\n",
      "-------------------------------------------------------------------------------------\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_142 (TimeDi (None, None, 29, 72)      2664      \n",
      "_________________________________________________________________\n",
      "time_distributed_143 (TimeDi (None, None, 27, 32)      6944      \n",
      "_________________________________________________________________\n",
      "time_distributed_144 (TimeDi (None, None, 27, 32)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_145 (TimeDi (None, None, 3, 32)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed_146 (TimeDi (None, None, 96)          0         \n",
      "_________________________________________________________________\n",
      "lstm_28 (LSTM)               (None, 170)               181560    \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 64)                10944     \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 202,502\n",
      "Trainable params: 202,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      " 20%|██        | 2/10 [18:35<1:17:47, 583.42s/it, best loss: -0.9436715303698676]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/temp_model.py:195: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  validation_data=(X_val_d, Y_val_d))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/40\n",
      " - 20s - loss: 0.9011 - acc: 0.6246 - val_loss: 0.4400 - val_acc: 0.7631\n",
      "\n",
      "Epoch 2/40\n",
      " - 12s - loss: 0.6237 - acc: 0.7312 - val_loss: 0.6144 - val_acc: 0.7153\n",
      "\n",
      "Epoch 3/40\n",
      " - 12s - loss: 0.5939 - acc: 0.7244 - val_loss: 0.4832 - val_acc: 0.7520\n",
      "\n",
      "Epoch 4/40\n",
      " - 12s - loss: 0.5499 - acc: 0.7327 - val_loss: 0.4673 - val_acc: 0.7418\n",
      "\n",
      "Epoch 5/40\n",
      " - 12s - loss: 0.4835 - acc: 0.7565 - val_loss: 0.4475 - val_acc: 0.7418\n",
      "\n",
      "Epoch 6/40\n",
      " - 12s - loss: 0.5334 - acc: 0.7361 - val_loss: 0.4933 - val_acc: 0.7526\n",
      "\n",
      "Epoch 7/40\n",
      " - 12s - loss: 0.5034 - acc: 0.7486 - val_loss: 0.4401 - val_acc: 0.7621\n",
      "\n",
      "Epoch 8/40\n",
      " - 12s - loss: 0.4910 - acc: 0.7587 - val_loss: 0.5595 - val_acc: 0.7710\n",
      "\n",
      "Epoch 9/40\n",
      " - 12s - loss: 0.5317 - acc: 0.7461 - val_loss: 0.4896 - val_acc: 0.7665\n",
      "\n",
      "Epoch 10/40\n",
      " - 12s - loss: 0.5557 - acc: 0.7421 - val_loss: 0.4851 - val_acc: 0.7594\n",
      "\n",
      "Epoch 11/40\n",
      " - 12s - loss: 0.4813 - acc: 0.7511 - val_loss: 0.4966 - val_acc: 0.7553\n",
      "\n",
      "Epoch 12/40\n",
      " - 12s - loss: 0.4903 - acc: 0.7591 - val_loss: 0.5170 - val_acc: 0.7489\n",
      "\n",
      "Epoch 13/40\n",
      " - 12s - loss: 0.5578 - acc: 0.7478 - val_loss: 0.5607 - val_acc: 0.7557\n",
      "\n",
      "Epoch 14/40\n",
      " - 12s - loss: 0.4919 - acc: 0.7550 - val_loss: 0.5210 - val_acc: 0.7340\n",
      "\n",
      "Epoch 15/40\n",
      " - 12s - loss: 0.4703 - acc: 0.7586 - val_loss: 0.6638 - val_acc: 0.7469\n",
      "\n",
      "Epoch 16/40\n",
      " - 12s - loss: 0.5889 - acc: 0.7397 - val_loss: 0.5505 - val_acc: 0.7520\n",
      "\n",
      "Epoch 17/40\n",
      " - 12s - loss: 0.4980 - acc: 0.7564 - val_loss: 0.5771 - val_acc: 0.7587\n",
      "\n",
      "Epoch 18/40\n",
      " - 12s - loss: 0.4779 - acc: 0.7527 - val_loss: 0.5650 - val_acc: 0.7516\n",
      "\n",
      "Epoch 19/40\n",
      " - 12s - loss: 0.4759 - acc: 0.7606 - val_loss: 0.7901 - val_acc: 0.7363\n",
      "\n",
      "Epoch 20/40\n",
      " - 11s - loss: 0.5025 - acc: 0.7558 - val_loss: 0.6613 - val_acc: 0.7662\n",
      "\n",
      "Epoch 21/40\n",
      " - 12s - loss: 0.5781 - acc: 0.7446 - val_loss: 0.6094 - val_acc: 0.7584\n",
      "\n",
      "Epoch 22/40\n",
      " - 12s - loss: 0.5101 - acc: 0.7535 - val_loss: 0.6726 - val_acc: 0.7384\n",
      "\n",
      "Epoch 23/40\n",
      " - 12s - loss: 0.4921 - acc: 0.7522 - val_loss: 0.6427 - val_acc: 0.7391\n",
      "\n",
      "Epoch 24/40\n",
      " - 12s - loss: 0.4695 - acc: 0.7599 - val_loss: 0.6448 - val_acc: 0.7587\n",
      "\n",
      "Epoch 25/40\n",
      " - 12s - loss: 0.5195 - acc: 0.7527 - val_loss: 0.6341 - val_acc: 0.7547\n",
      "\n",
      "Epoch 26/40\n",
      " - 11s - loss: 0.5767 - acc: 0.7402 - val_loss: 0.7702 - val_acc: 0.6359\n",
      "\n",
      "Epoch 27/40\n",
      " - 12s - loss: 0.4964 - acc: 0.7578 - val_loss: 0.8162 - val_acc: 0.6610\n",
      "\n",
      "Epoch 28/40\n",
      " - 12s - loss: 0.4901 - acc: 0.7567 - val_loss: 0.6006 - val_acc: 0.7540\n",
      "\n",
      "Epoch 29/40\n",
      " - 12s - loss: 0.4645 - acc: 0.7539 - val_loss: 0.7034 - val_acc: 0.7615\n",
      "\n",
      "Epoch 30/40\n",
      " - 12s - loss: 0.4859 - acc: 0.7599 - val_loss: 0.7634 - val_acc: 0.7506\n",
      "\n",
      "Epoch 31/40\n",
      " - 12s - loss: 0.4710 - acc: 0.7640 - val_loss: 0.8163 - val_acc: 0.6050\n",
      "\n",
      "Epoch 32/40\n",
      " - 12s - loss: 0.4763 - acc: 0.7594 - val_loss: 0.7883 - val_acc: 0.7397\n",
      "\n",
      "Epoch 33/40\n",
      " - 12s - loss: 0.5176 - acc: 0.7447 - val_loss: 0.6728 - val_acc: 0.7526\n",
      "\n",
      "Epoch 34/40\n",
      " - 12s - loss: 0.4829 - acc: 0.7527 - val_loss: 0.8170 - val_acc: 0.7472\n",
      "\n",
      "Epoch 35/40\n",
      " - 12s - loss: 0.4942 - acc: 0.7582 - val_loss: 0.8518 - val_acc: 0.6308\n",
      "\n",
      "Epoch 36/40\n",
      " - 12s - loss: 0.5025 - acc: 0.7595 - val_loss: 0.7278 - val_acc: 0.6322\n",
      "\n",
      "Epoch 37/40\n",
      " - 12s - loss: 0.4953 - acc: 0.7582 - val_loss: 0.8089 - val_acc: 0.6295\n",
      "\n",
      "Epoch 38/40\n",
      " - 12s - loss: 0.5012 - acc: 0.7614 - val_loss: 0.7226 - val_acc: 0.7706\n",
      "\n",
      "Epoch 39/40\n",
      " - 12s - loss: 0.5327 - acc: 0.7576 - val_loss: 0.6259 - val_acc: 0.7774\n",
      "\n",
      "Epoch 40/40\n",
      " - 12s - loss: 0.5133 - acc: 0.7421 - val_loss: 0.7500 - val_acc: 0.7693\n",
      "\n",
      "Train accuracy\n",
      "0.8045429815016322\n",
      "Test accuracy:\n",
      "0.7692568713946386\n",
      "-------------------------------------------------------------------------------------\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_147 (TimeDi (None, None, 29, 72)      2664      \n",
      "_________________________________________________________________\n",
      "time_distributed_148 (TimeDi (None, None, 27, 32)      6944      \n",
      "_________________________________________________________________\n",
      "time_distributed_149 (TimeDi (None, None, 27, 32)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_150 (TimeDi (None, None, 4, 32)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed_151 (TimeDi (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_29 (LSTM)               (None, 170)               203320    \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 64)                10944     \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 224,262\n",
      "Trainable params: 224,262\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      " 30%|███       | 3/10 [26:40<1:04:37, 553.90s/it, best loss: -0.9436715303698676]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/temp_model.py:195: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  validation_data=(X_val_d, Y_val_d))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/40\n",
      " - 22s - loss: 0.3549 - acc: 0.8580 - val_loss: 0.2547 - val_acc: 0.9050\n",
      "\n",
      "Epoch 2/40\n",
      " - 13s - loss: 0.1932 - acc: 0.9283 - val_loss: 0.2296 - val_acc: 0.9155\n",
      "\n",
      "Epoch 3/40\n",
      " - 12s - loss: 0.1479 - acc: 0.9404 - val_loss: 0.3933 - val_acc: 0.9063\n",
      "\n",
      "Epoch 4/40\n",
      " - 12s - loss: 0.1468 - acc: 0.9404 - val_loss: 0.2393 - val_acc: 0.9284\n",
      "\n",
      "Epoch 5/40\n",
      " - 12s - loss: 0.1491 - acc: 0.9426 - val_loss: 0.2597 - val_acc: 0.9087\n",
      "\n",
      "Epoch 6/40\n",
      " - 11s - loss: 0.1274 - acc: 0.9449 - val_loss: 0.2597 - val_acc: 0.9165\n",
      "\n",
      "Epoch 7/40\n",
      " - 11s - loss: 0.1531 - acc: 0.9400 - val_loss: 0.4924 - val_acc: 0.8673\n",
      "\n",
      "Epoch 8/40\n",
      " - 12s - loss: 0.1380 - acc: 0.9388 - val_loss: 0.3308 - val_acc: 0.9203\n",
      "\n",
      "Epoch 9/40\n",
      " - 12s - loss: 0.1294 - acc: 0.9453 - val_loss: 0.2917 - val_acc: 0.9080\n",
      "\n",
      "Epoch 10/40\n",
      " - 12s - loss: 0.1184 - acc: 0.9504 - val_loss: 0.3128 - val_acc: 0.9121\n",
      "\n",
      "Epoch 11/40\n",
      " - 12s - loss: 0.1191 - acc: 0.9487 - val_loss: 0.3358 - val_acc: 0.9175\n",
      "\n",
      "Epoch 12/40\n",
      " - 12s - loss: 0.1377 - acc: 0.9429 - val_loss: 0.4665 - val_acc: 0.8734\n",
      "\n",
      "Epoch 13/40\n",
      " - 12s - loss: 0.1098 - acc: 0.9539 - val_loss: 0.2623 - val_acc: 0.9223\n",
      "\n",
      "Epoch 14/40\n",
      " - 12s - loss: 0.2217 - acc: 0.9272 - val_loss: 0.2455 - val_acc: 0.9240\n",
      "\n",
      "Epoch 15/40\n",
      " - 12s - loss: 0.1550 - acc: 0.9414 - val_loss: 0.2928 - val_acc: 0.9104\n",
      "\n",
      "Epoch 16/40\n",
      " - 12s - loss: 0.1313 - acc: 0.9457 - val_loss: 0.2615 - val_acc: 0.9250\n",
      "\n",
      "Epoch 17/40\n",
      " - 12s - loss: 0.1244 - acc: 0.9514 - val_loss: 0.2582 - val_acc: 0.9209\n",
      "\n",
      "Epoch 18/40\n",
      " - 12s - loss: 0.1248 - acc: 0.9470 - val_loss: 0.2555 - val_acc: 0.9328\n",
      "\n",
      "Epoch 19/40\n",
      " - 12s - loss: 0.1171 - acc: 0.9525 - val_loss: 0.2676 - val_acc: 0.9267\n",
      "\n",
      "Epoch 20/40\n",
      " - 12s - loss: 0.1422 - acc: 0.9449 - val_loss: 0.3411 - val_acc: 0.9030\n",
      "\n",
      "Epoch 21/40\n",
      " - 12s - loss: 0.2044 - acc: 0.9298 - val_loss: 0.2676 - val_acc: 0.9162\n",
      "\n",
      "Epoch 22/40\n",
      " - 12s - loss: 0.1485 - acc: 0.9406 - val_loss: 0.2444 - val_acc: 0.9165\n",
      "\n",
      "Epoch 23/40\n",
      " - 12s - loss: 0.1496 - acc: 0.9422 - val_loss: 0.2181 - val_acc: 0.9213\n",
      "\n",
      "Epoch 24/40\n",
      " - 12s - loss: 0.1126 - acc: 0.9498 - val_loss: 0.2552 - val_acc: 0.9308\n",
      "\n",
      "Epoch 25/40\n",
      " - 12s - loss: 0.1326 - acc: 0.9479 - val_loss: 0.2903 - val_acc: 0.9189\n",
      "\n",
      "Epoch 26/40\n",
      " - 12s - loss: 0.1258 - acc: 0.9501 - val_loss: 0.3500 - val_acc: 0.9209\n",
      "\n",
      "Epoch 27/40\n",
      " - 12s - loss: 0.1379 - acc: 0.9467 - val_loss: 0.3000 - val_acc: 0.9179\n",
      "\n",
      "Epoch 28/40\n",
      " - 13s - loss: 0.1724 - acc: 0.9421 - val_loss: 0.2736 - val_acc: 0.9328\n",
      "\n",
      "Epoch 29/40\n",
      " - 12s - loss: 0.1413 - acc: 0.9499 - val_loss: 0.3411 - val_acc: 0.9060\n",
      "\n",
      "Epoch 30/40\n",
      " - 13s - loss: 0.1309 - acc: 0.9484 - val_loss: 0.2910 - val_acc: 0.9196\n",
      "\n",
      "Epoch 31/40\n",
      " - 13s - loss: 0.1374 - acc: 0.9483 - val_loss: 0.2765 - val_acc: 0.9253\n",
      "\n",
      "Epoch 32/40\n",
      " - 12s - loss: 0.1146 - acc: 0.9539 - val_loss: 0.2874 - val_acc: 0.9264\n",
      "\n",
      "Epoch 33/40\n",
      " - 12s - loss: 0.1856 - acc: 0.9334 - val_loss: 0.2772 - val_acc: 0.9216\n",
      "\n",
      "Epoch 34/40\n",
      " - 12s - loss: 0.1407 - acc: 0.9425 - val_loss: 0.3601 - val_acc: 0.9023\n",
      "\n",
      "Epoch 35/40\n",
      " - 12s - loss: 0.1381 - acc: 0.9444 - val_loss: 0.2877 - val_acc: 0.9274\n",
      "\n",
      "Epoch 36/40\n",
      " - 12s - loss: 0.1334 - acc: 0.9502 - val_loss: 0.3195 - val_acc: 0.9257\n",
      "\n",
      "Epoch 37/40\n",
      " - 12s - loss: 0.1596 - acc: 0.9402 - val_loss: 0.3567 - val_acc: 0.9179\n",
      "\n",
      "Epoch 38/40\n",
      " - 12s - loss: 0.1229 - acc: 0.9495 - val_loss: 0.3507 - val_acc: 0.9084\n",
      "\n",
      "Epoch 39/40\n",
      " - 12s - loss: 0.1573 - acc: 0.9397 - val_loss: 0.3693 - val_acc: 0.9243\n",
      "\n",
      "Epoch 40/40\n",
      " - 12s - loss: 0.1572 - acc: 0.9372 - val_loss: 0.3153 - val_acc: 0.9226\n",
      "\n",
      "Train accuracy\n",
      "0.9552502719699623\n",
      "Test accuracy:\n",
      "0.9226331862911435\n",
      "-------------------------------------------------------------------------------------\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_152 (TimeDi (None, None, 29, 72)      2664      \n",
      "_________________________________________________________________\n",
      "time_distributed_153 (TimeDi (None, None, 27, 32)      6944      \n",
      "_________________________________________________________________\n",
      "time_distributed_154 (TimeDi (None, None, 27, 32)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_155 (TimeDi (None, None, 3, 32)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed_156 (TimeDi (None, None, 96)          0         \n",
      "_________________________________________________________________\n",
      "lstm_30 (LSTM)               (None, 170)               181560    \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 64)                10944     \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 202,502\n",
      "Trainable params: 202,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      " 40%|████      | 4/10 [34:57<53:41, 536.87s/it, best loss: -0.9436715303698676]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/temp_model.py:195: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  validation_data=(X_val_d, Y_val_d))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/40\n",
      " - 21s - loss: 0.9451 - acc: 0.5835 - val_loss: 0.7053 - val_acc: 0.5972\n",
      "\n",
      "Epoch 2/40\n",
      " - 11s - loss: 0.5887 - acc: 0.7276 - val_loss: 0.4855 - val_acc: 0.7438\n",
      "\n",
      "Epoch 3/40\n",
      " - 11s - loss: 0.6682 - acc: 0.7218 - val_loss: 0.5546 - val_acc: 0.7370\n",
      "\n",
      "Epoch 4/40\n",
      " - 11s - loss: 0.5608 - acc: 0.7327 - val_loss: 0.5004 - val_acc: 0.7458\n",
      "\n",
      "Epoch 5/40\n",
      " - 12s - loss: 0.5944 - acc: 0.7176 - val_loss: 0.5717 - val_acc: 0.7194\n",
      "\n",
      "Epoch 6/40\n",
      " - 12s - loss: 0.5490 - acc: 0.7379 - val_loss: 0.4713 - val_acc: 0.7455\n",
      "\n",
      "Epoch 7/40\n",
      " - 12s - loss: 0.5410 - acc: 0.7354 - val_loss: 0.4936 - val_acc: 0.7363\n",
      "\n",
      "Epoch 8/40\n",
      " - 12s - loss: 0.5453 - acc: 0.7477 - val_loss: 0.4476 - val_acc: 0.7618\n",
      "\n",
      "Epoch 9/40\n",
      " - 12s - loss: 0.5443 - acc: 0.7428 - val_loss: 0.4821 - val_acc: 0.7329\n",
      "\n",
      "Epoch 10/40\n",
      " - 11s - loss: 0.5065 - acc: 0.7473 - val_loss: 0.4900 - val_acc: 0.7574\n",
      "\n",
      "Epoch 11/40\n",
      " - 11s - loss: 0.5316 - acc: 0.7383 - val_loss: 0.4727 - val_acc: 0.7177\n",
      "\n",
      "Epoch 12/40\n",
      " - 11s - loss: 0.5373 - acc: 0.7442 - val_loss: 0.5280 - val_acc: 0.7720\n",
      "\n",
      "Epoch 13/40\n",
      " - 12s - loss: 0.5314 - acc: 0.7424 - val_loss: 0.5773 - val_acc: 0.7513\n",
      "\n",
      "Epoch 14/40\n",
      " - 12s - loss: 0.5821 - acc: 0.7318 - val_loss: 0.5359 - val_acc: 0.7587\n",
      "\n",
      "Epoch 15/40\n",
      " - 12s - loss: 0.5417 - acc: 0.7422 - val_loss: 0.5578 - val_acc: 0.7557\n",
      "\n",
      "Epoch 16/40\n",
      " - 12s - loss: 0.5653 - acc: 0.7492 - val_loss: 0.5992 - val_acc: 0.7384\n",
      "\n",
      "Epoch 17/40\n",
      " - 12s - loss: 0.5690 - acc: 0.7322 - val_loss: 0.5097 - val_acc: 0.7553\n",
      "\n",
      "Epoch 18/40\n",
      " - 12s - loss: 0.5392 - acc: 0.7384 - val_loss: 0.5316 - val_acc: 0.7139\n",
      "\n",
      "Epoch 19/40\n",
      " - 12s - loss: 0.5965 - acc: 0.7412 - val_loss: 0.5660 - val_acc: 0.7248\n",
      "\n",
      "Epoch 20/40\n",
      " - 12s - loss: 0.5566 - acc: 0.7428 - val_loss: 0.5762 - val_acc: 0.6658\n",
      "\n",
      "Epoch 21/40\n",
      " - 11s - loss: 0.5306 - acc: 0.7429 - val_loss: 0.5387 - val_acc: 0.7099\n",
      "\n",
      "Epoch 22/40\n",
      " - 12s - loss: 0.5723 - acc: 0.7310 - val_loss: 0.4788 - val_acc: 0.7686\n",
      "\n",
      "Epoch 23/40\n",
      " - 12s - loss: 0.5623 - acc: 0.7526 - val_loss: 0.5781 - val_acc: 0.7367\n",
      "\n",
      "Epoch 24/40\n",
      " - 12s - loss: 0.5214 - acc: 0.7579 - val_loss: 0.5458 - val_acc: 0.7469\n",
      "\n",
      "Epoch 25/40\n",
      " - 12s - loss: 0.5131 - acc: 0.7524 - val_loss: 0.5348 - val_acc: 0.7672\n",
      "\n",
      "Epoch 26/40\n",
      " - 11s - loss: 0.4927 - acc: 0.7508 - val_loss: 0.5920 - val_acc: 0.7492\n",
      "\n",
      "Epoch 27/40\n",
      " - 12s - loss: 0.4623 - acc: 0.7602 - val_loss: 0.6645 - val_acc: 0.7699\n",
      "\n",
      "Epoch 28/40\n",
      " - 11s - loss: 0.4842 - acc: 0.7511 - val_loss: 0.6208 - val_acc: 0.7116\n",
      "\n",
      "Epoch 29/40\n",
      " - 11s - loss: 0.5815 - acc: 0.7315 - val_loss: 0.6390 - val_acc: 0.6376\n",
      "\n",
      "Epoch 30/40\n",
      " - 12s - loss: 0.5494 - acc: 0.7442 - val_loss: 0.5983 - val_acc: 0.7146\n",
      "\n",
      "Epoch 31/40\n",
      " - 11s - loss: 0.8988 - acc: 0.6616 - val_loss: 0.8617 - val_acc: 0.6121\n",
      "\n",
      "Epoch 32/40\n",
      " - 11s - loss: 0.8179 - acc: 0.6163 - val_loss: 0.8999 - val_acc: 0.4869\n",
      "\n",
      "Epoch 33/40\n",
      " - 11s - loss: 0.7863 - acc: 0.6211 - val_loss: 0.8022 - val_acc: 0.5643\n",
      "\n",
      "Epoch 34/40\n",
      " - 11s - loss: 0.7817 - acc: 0.6213 - val_loss: 0.7390 - val_acc: 0.5769\n",
      "\n",
      "Epoch 35/40\n",
      " - 11s - loss: 0.7476 - acc: 0.6268 - val_loss: 0.7986 - val_acc: 0.6108\n",
      "\n",
      "Epoch 36/40\n",
      " - 11s - loss: 0.7430 - acc: 0.6211 - val_loss: 0.7654 - val_acc: 0.6026\n",
      "\n",
      "Epoch 37/40\n",
      " - 11s - loss: 0.7086 - acc: 0.6311 - val_loss: 0.8905 - val_acc: 0.4998\n",
      "\n",
      "Epoch 38/40\n",
      " - 11s - loss: 0.6924 - acc: 0.6360 - val_loss: 0.8332 - val_acc: 0.4822\n",
      "\n",
      "Epoch 39/40\n",
      " - 11s - loss: 0.6919 - acc: 0.6330 - val_loss: 0.8900 - val_acc: 0.4788\n",
      "\n",
      "Epoch 40/40\n",
      " - 12s - loss: 0.7077 - acc: 0.6326 - val_loss: 0.7084 - val_acc: 0.6057\n",
      "\n",
      "Train accuracy\n",
      "0.6474428726877041\n",
      "Test accuracy:\n",
      "0.6057007125890737\n",
      "-------------------------------------------------------------------------------------\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_157 (TimeDi (None, None, 29, 72)      2664      \n",
      "_________________________________________________________________\n",
      "time_distributed_158 (TimeDi (None, None, 27, 32)      6944      \n",
      "_________________________________________________________________\n",
      "time_distributed_159 (TimeDi (None, None, 27, 32)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_160 (TimeDi (None, None, 5, 32)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed_161 (TimeDi (None, None, 160)         0         \n",
      "_________________________________________________________________\n",
      "lstm_31 (LSTM)               (None, 170)               225080    \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 64)                10944     \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 246,022\n",
      "Trainable params: 246,022\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      " 50%|█████     | 5/10 [42:52<43:11, 518.26s/it, best loss: -0.9436715303698676]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/temp_model.py:195: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  validation_data=(X_val_d, Y_val_d))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/40\n",
      " - 22s - loss: 0.5000 - acc: 0.7934 - val_loss: 0.2935 - val_acc: 0.9026\n",
      "\n",
      "Epoch 2/40\n",
      " - 12s - loss: 0.2180 - acc: 0.9166 - val_loss: 0.3167 - val_acc: 0.8968\n",
      "\n",
      "Epoch 3/40\n",
      " - 12s - loss: 0.1742 - acc: 0.9324 - val_loss: 0.3287 - val_acc: 0.8778\n",
      "\n",
      "Epoch 4/40\n",
      " - 12s - loss: 0.1507 - acc: 0.9397 - val_loss: 0.2940 - val_acc: 0.9077\n",
      "\n",
      "Epoch 5/40\n",
      " - 12s - loss: 0.1535 - acc: 0.9354 - val_loss: 0.2733 - val_acc: 0.9145\n",
      "\n",
      "Epoch 6/40\n",
      " - 12s - loss: 0.1522 - acc: 0.9410 - val_loss: 0.3087 - val_acc: 0.9070\n",
      "\n",
      "Epoch 7/40\n",
      " - 12s - loss: 0.1393 - acc: 0.9423 - val_loss: 0.3181 - val_acc: 0.9074\n",
      "\n",
      "Epoch 8/40\n",
      " - 12s - loss: 0.1287 - acc: 0.9482 - val_loss: 0.2818 - val_acc: 0.9080\n",
      "\n",
      "Epoch 9/40\n",
      " - 12s - loss: 0.1378 - acc: 0.9464 - val_loss: 0.2930 - val_acc: 0.9165\n",
      "\n",
      "Epoch 10/40\n",
      " - 12s - loss: 0.1367 - acc: 0.9464 - val_loss: 0.2727 - val_acc: 0.9220\n",
      "\n",
      "Epoch 11/40\n",
      " - 12s - loss: 0.1273 - acc: 0.9493 - val_loss: 0.3332 - val_acc: 0.9155\n",
      "\n",
      "Epoch 12/40\n",
      " - 12s - loss: 0.1294 - acc: 0.9470 - val_loss: 0.3618 - val_acc: 0.9036\n",
      "\n",
      "Epoch 13/40\n",
      " - 13s - loss: 0.1290 - acc: 0.9486 - val_loss: 0.3128 - val_acc: 0.9189\n",
      "\n",
      "Epoch 14/40\n",
      " - 12s - loss: 0.1132 - acc: 0.9494 - val_loss: 0.4411 - val_acc: 0.9050\n",
      "\n",
      "Epoch 15/40\n",
      " - 12s - loss: 0.1264 - acc: 0.9470 - val_loss: 0.3379 - val_acc: 0.9111\n",
      "\n",
      "Epoch 16/40\n",
      " - 12s - loss: 0.1127 - acc: 0.9505 - val_loss: 0.3078 - val_acc: 0.9237\n",
      "\n",
      "Epoch 17/40\n",
      " - 12s - loss: 0.1144 - acc: 0.9532 - val_loss: 0.4058 - val_acc: 0.9131\n",
      "\n",
      "Epoch 18/40\n",
      " - 12s - loss: 0.1133 - acc: 0.9510 - val_loss: 0.3878 - val_acc: 0.9165\n",
      "\n",
      "Epoch 19/40\n",
      " - 12s - loss: 0.1230 - acc: 0.9504 - val_loss: 0.4667 - val_acc: 0.8948\n",
      "\n",
      "Epoch 20/40\n",
      " - 12s - loss: 0.1042 - acc: 0.9548 - val_loss: 0.3399 - val_acc: 0.9220\n",
      "\n",
      "Epoch 21/40\n",
      " - 12s - loss: 0.1196 - acc: 0.9486 - val_loss: 0.4097 - val_acc: 0.9074\n",
      "\n",
      "Epoch 22/40\n",
      " - 12s - loss: 0.1104 - acc: 0.9542 - val_loss: 0.4327 - val_acc: 0.9121\n",
      "\n",
      "Epoch 23/40\n",
      " - 12s - loss: 0.1114 - acc: 0.9546 - val_loss: 0.3745 - val_acc: 0.9165\n",
      "\n",
      "Epoch 24/40\n",
      " - 13s - loss: 0.0960 - acc: 0.9597 - val_loss: 0.3417 - val_acc: 0.9118\n",
      "\n",
      "Epoch 25/40\n",
      " - 12s - loss: 0.1025 - acc: 0.9596 - val_loss: 0.3727 - val_acc: 0.9165\n",
      "\n",
      "Epoch 26/40\n",
      " - 12s - loss: 0.0988 - acc: 0.9606 - val_loss: 0.4977 - val_acc: 0.8873\n",
      "\n",
      "Epoch 27/40\n",
      " - 12s - loss: 0.1038 - acc: 0.9581 - val_loss: 0.3671 - val_acc: 0.9209\n",
      "\n",
      "Epoch 28/40\n",
      " - 13s - loss: 0.1036 - acc: 0.9578 - val_loss: 0.3836 - val_acc: 0.9182\n",
      "\n",
      "Epoch 29/40\n",
      " - 13s - loss: 0.1030 - acc: 0.9565 - val_loss: 0.4232 - val_acc: 0.9080\n",
      "\n",
      "Epoch 30/40\n",
      " - 12s - loss: 0.0996 - acc: 0.9606 - val_loss: 0.3364 - val_acc: 0.9260\n",
      "\n",
      "Epoch 31/40\n",
      " - 12s - loss: 0.0801 - acc: 0.9626 - val_loss: 0.3910 - val_acc: 0.9260\n",
      "\n",
      "Epoch 32/40\n",
      " - 12s - loss: 0.0835 - acc: 0.9629 - val_loss: 0.4065 - val_acc: 0.9209\n",
      "\n",
      "Epoch 33/40\n",
      " - 12s - loss: 0.0852 - acc: 0.9644 - val_loss: 0.3813 - val_acc: 0.9175\n",
      "\n",
      "Epoch 34/40\n",
      " - 12s - loss: 0.0846 - acc: 0.9640 - val_loss: 0.4216 - val_acc: 0.9220\n",
      "\n",
      "Epoch 35/40\n",
      " - 12s - loss: 0.0866 - acc: 0.9645 - val_loss: 0.4775 - val_acc: 0.9040\n",
      "\n",
      "Epoch 36/40\n",
      " - 12s - loss: 0.0895 - acc: 0.9607 - val_loss: 0.4200 - val_acc: 0.9080\n",
      "\n",
      "Epoch 37/40\n",
      " - 12s - loss: 0.0786 - acc: 0.9645 - val_loss: 0.4423 - val_acc: 0.9053\n",
      "\n",
      "Epoch 38/40\n",
      " - 12s - loss: 0.0772 - acc: 0.9650 - val_loss: 0.4006 - val_acc: 0.9182\n",
      "\n",
      "Epoch 39/40\n",
      " - 12s - loss: 0.0774 - acc: 0.9656 - val_loss: 0.4126 - val_acc: 0.9206\n",
      "\n",
      "Epoch 40/40\n",
      " - 12s - loss: 0.0872 - acc: 0.9629 - val_loss: 0.4269 - val_acc: 0.9114\n",
      "\n",
      "Train accuracy\n",
      "0.969532100108814\n",
      "Test accuracy:\n",
      "0.9114353579911775\n",
      "-------------------------------------------------------------------------------------\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_162 (TimeDi (None, None, 29, 72)      2664      \n",
      "_________________________________________________________________\n",
      "time_distributed_163 (TimeDi (None, None, 27, 32)      6944      \n",
      "_________________________________________________________________\n",
      "time_distributed_164 (TimeDi (None, None, 27, 32)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_165 (TimeDi (None, None, 3, 32)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed_166 (TimeDi (None, None, 96)          0         \n",
      "_________________________________________________________________\n",
      "lstm_32 (LSTM)               (None, 170)               181560    \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 64)                10944     \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 202,502\n",
      "Trainable params: 202,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      " 60%|██████    | 6/10 [51:18<34:17, 514.42s/it, best loss: -0.9436715303698676]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/temp_model.py:195: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  validation_data=(X_val_d, Y_val_d))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/40\n",
      " - 22s - loss: 1.3850 - acc: 0.4388 - val_loss: 0.9047 - val_acc: 0.5154\n",
      "\n",
      "Epoch 2/40\n",
      " - 12s - loss: 1.1341 - acc: 0.4713 - val_loss: 0.8539 - val_acc: 0.5144\n",
      "\n",
      "Epoch 3/40\n",
      " - 11s - loss: 1.0099 - acc: 0.4849 - val_loss: 0.8429 - val_acc: 0.5063\n",
      "\n",
      "Epoch 4/40\n",
      " - 11s - loss: 1.0948 - acc: 0.4682 - val_loss: 0.8714 - val_acc: 0.5144\n",
      "\n",
      "Epoch 5/40\n",
      " - 11s - loss: 1.0909 - acc: 0.4697 - val_loss: 0.8832 - val_acc: 0.5256\n",
      "\n",
      "Epoch 6/40\n",
      " - 11s - loss: 1.1281 - acc: 0.4833 - val_loss: 1.1885 - val_acc: 0.5171\n",
      "\n",
      "Epoch 9/40\n",
      " - 12s - loss: 1.0969 - acc: 0.4716 - val_loss: 1.8223 - val_acc: 0.3370\n",
      "\n",
      "Epoch 10/40\n",
      " - 11s - loss: 1.0356 - acc: 0.4812 - val_loss: 0.9267 - val_acc: 0.5256\n",
      "\n",
      "Epoch 11/40\n",
      " - 11s - loss: 1.0218 - acc: 0.4971 - val_loss: 1.1785 - val_acc: 0.4571\n",
      "\n",
      "Epoch 12/40\n",
      " - 11s - loss: 1.0037 - acc: 0.4822 - val_loss: 0.9930 - val_acc: 0.5300\n",
      "\n",
      "Epoch 13/40\n",
      " - 11s - loss: 1.0738 - acc: 0.4859 - val_loss: 0.9307 - val_acc: 0.5178\n",
      "\n",
      "Epoch 14/40\n",
      " - 12s - loss: 1.0587 - acc: 0.4737 - val_loss: 0.9142 - val_acc: 0.5090\n",
      "\n",
      "Epoch 15/40\n",
      " - 11s - loss: 1.0373 - acc: 0.4786 - val_loss: 1.0751 - val_acc: 0.4873\n",
      "\n",
      "Epoch 16/40\n",
      " - 12s - loss: 1.0559 - acc: 0.4807 - val_loss: 0.9404 - val_acc: 0.4995\n",
      "\n",
      "Epoch 17/40\n",
      " - 11s - loss: 1.1214 - acc: 0.4680 - val_loss: 0.9722 - val_acc: 0.5151\n",
      "\n",
      "Epoch 18/40\n",
      " - 12s - loss: 1.1035 - acc: 0.4712 - val_loss: 1.0020 - val_acc: 0.4927\n",
      "\n",
      "Epoch 19/40\n",
      " - 12s - loss: 1.1367 - acc: 0.4699 - val_loss: 1.1679 - val_acc: 0.5053\n",
      "\n",
      "Epoch 20/40\n",
      " - 12s - loss: 1.1781 - acc: 0.4695 - val_loss: 0.9031 - val_acc: 0.4907\n",
      "\n",
      "Epoch 21/40\n",
      " - 11s - loss: 1.1584 - acc: 0.4736 - val_loss: 0.8615 - val_acc: 0.5131\n",
      "\n",
      "Epoch 22/40\n",
      " - 11s - loss: 1.1361 - acc: 0.4743 - val_loss: 0.8945 - val_acc: 0.5215\n",
      "\n",
      "Epoch 23/40\n",
      " - 11s - loss: 1.0807 - acc: 0.4631 - val_loss: 0.9099 - val_acc: 0.5243\n",
      "\n",
      "Epoch 24/40\n",
      " - 11s - loss: 1.0737 - acc: 0.4698 - val_loss: 0.9201 - val_acc: 0.5134\n",
      "\n",
      "Epoch 25/40\n",
      " - 11s - loss: 1.1073 - acc: 0.4701 - val_loss: 0.9166 - val_acc: 0.5246\n",
      "\n",
      "Epoch 26/40\n",
      " - 11s - loss: 1.1192 - acc: 0.4591 - val_loss: 0.8694 - val_acc: 0.5287\n",
      "\n",
      "Epoch 27/40\n",
      " - 12s - loss: 1.1344 - acc: 0.4531 - val_loss: 1.0244 - val_acc: 0.4832\n",
      "\n",
      "Epoch 28/40\n",
      " - 11s - loss: 1.1323 - acc: 0.4555 - val_loss: 0.8870 - val_acc: 0.5195\n",
      "\n",
      "Epoch 29/40\n",
      " - 12s - loss: 1.1604 - acc: 0.4603 - val_loss: 0.9463 - val_acc: 0.5158\n",
      "\n",
      "Epoch 30/40\n",
      " - 11s - loss: 1.1162 - acc: 0.4705 - val_loss: 0.9085 - val_acc: 0.5175\n",
      "\n",
      "Epoch 31/40\n",
      " - 11s - loss: 1.1262 - acc: 0.4563 - val_loss: 0.8360 - val_acc: 0.5287\n",
      "\n",
      "Epoch 32/40\n",
      " - 11s - loss: 1.1362 - acc: 0.4589 - val_loss: 0.9146 - val_acc: 0.5232\n",
      "\n",
      "Epoch 33/40\n",
      " - 11s - loss: 1.1203 - acc: 0.4635 - val_loss: 0.8781 - val_acc: 0.5256\n",
      "\n",
      "Epoch 34/40\n",
      " - 11s - loss: 1.1566 - acc: 0.4502 - val_loss: 1.9809 - val_acc: 0.3346\n",
      "\n",
      "Epoch 35/40\n",
      " - 11s - loss: 1.0994 - acc: 0.4657 - val_loss: 1.7846 - val_acc: 0.3482\n",
      "\n",
      "Epoch 36/40\n",
      " - 12s - loss: 1.1200 - acc: 0.4599 - val_loss: 1.3733 - val_acc: 0.3556\n",
      "\n",
      "Epoch 37/40\n",
      " - 12s - loss: 1.1609 - acc: 0.4599 - val_loss: 1.5375 - val_acc: 0.3295\n",
      "\n",
      "Epoch 38/40\n",
      " - 11s - loss: 1.1823 - acc: 0.4555 - val_loss: 1.7175 - val_acc: 0.3227\n",
      "\n",
      "Epoch 39/40\n",
      " - 11s - loss: 1.1359 - acc: 0.4525 - val_loss: 1.0229 - val_acc: 0.5097\n",
      "\n",
      "Epoch 40/40\n",
      " - 12s - loss: 1.1174 - acc: 0.4495 - val_loss: 1.6677 - val_acc: 0.3400\n",
      "\n",
      "Train accuracy\n",
      "0.3482045701849837\n",
      "Test accuracy:\n",
      "0.340006786562606\n",
      "-------------------------------------------------------------------------------------\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_167 (TimeDi (None, None, 29, 72)      2664      \n",
      "_________________________________________________________________\n",
      "time_distributed_168 (TimeDi (None, None, 27, 32)      6944      \n",
      "_________________________________________________________________\n",
      "time_distributed_169 (TimeDi (None, None, 27, 32)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_170 (TimeDi (None, None, 5, 32)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed_171 (TimeDi (None, None, 160)         0         \n",
      "_________________________________________________________________\n",
      "lstm_33 (LSTM)               (None, 170)               225080    \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 64)                10944     \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 246,022\n",
      "Trainable params: 246,022\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      " 70%|███████   | 7/10 [59:09<25:04, 501.61s/it, best loss: -0.9436715303698676]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/temp_model.py:195: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  validation_data=(X_val_d, Y_val_d))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/40\n",
      " - 24s - loss: 3.0198 - acc: 0.2043 - val_loss: 2.0500 - val_acc: 0.0573\n",
      "\n",
      "Epoch 2/40\n",
      " - 12s - loss: 2.6333 - acc: 0.2278 - val_loss: 2.1834 - val_acc: 0.3339\n",
      "\n",
      "Epoch 3/40\n",
      " - 12s - loss: 2.5356 - acc: 0.2227 - val_loss: 2.4656 - val_acc: 0.2294\n",
      "\n",
      "Epoch 4/40\n",
      " - 12s - loss: 2.4777 - acc: 0.2274 - val_loss: 2.5650 - val_acc: 0.1805\n",
      "\n",
      "Epoch 5/40\n",
      " - 13s - loss: 2.6536 - acc: 0.2044 - val_loss: 2.5114 - val_acc: 0.2277\n",
      "\n",
      "Epoch 6/40\n",
      " - 12s - loss: 2.7222 - acc: 0.2033 - val_loss: 2.7133 - val_acc: 0.2396\n",
      "\n",
      "Epoch 7/40\n",
      " - 12s - loss: 2.5771 - acc: 0.1872 - val_loss: 2.4246 - val_acc: 0.2348\n",
      "\n",
      "Epoch 8/40\n",
      " - 13s - loss: 2.6127 - acc: 0.1961 - val_loss: 2.6498 - val_acc: 0.1666\n",
      "\n",
      "Epoch 9/40\n",
      " - 13s - loss: 2.5766 - acc: 0.1897 - val_loss: 2.8889 - val_acc: 0.1666\n",
      "\n",
      "Epoch 10/40\n",
      " - 12s - loss: 2.5613 - acc: 0.1907 - val_loss: 3.2998 - val_acc: 0.1666\n",
      "\n",
      "Epoch 11/40\n",
      " - 12s - loss: 2.5616 - acc: 0.1829 - val_loss: 3.5252 - val_acc: 0.1666\n",
      "\n",
      "Epoch 12/40\n",
      " - 13s - loss: 2.5896 - acc: 0.1921 - val_loss: 3.4835 - val_acc: 0.1666\n",
      "\n",
      "Epoch 13/40\n",
      " - 12s - loss: 2.5760 - acc: 0.1865 - val_loss: 3.8724 - val_acc: 0.1666\n",
      "\n",
      "Epoch 14/40\n",
      " - 12s - loss: 2.5842 - acc: 0.1873 - val_loss: 3.2276 - val_acc: 0.1666\n",
      "\n",
      "Epoch 15/40\n",
      " - 12s - loss: 2.5446 - acc: 0.1862 - val_loss: 3.6619 - val_acc: 0.1666\n",
      "\n",
      "Epoch 16/40\n",
      " - 12s - loss: 2.5325 - acc: 0.1884 - val_loss: 4.3423 - val_acc: 0.1666\n",
      "\n",
      "Epoch 17/40\n",
      " - 13s - loss: 2.6438 - acc: 0.1840 - val_loss: 4.1304 - val_acc: 0.1666\n",
      "\n",
      "Epoch 18/40\n",
      " - 13s - loss: 2.6172 - acc: 0.1851 - val_loss: 4.2349 - val_acc: 0.1666\n",
      "\n",
      "Epoch 19/40\n",
      " - 13s - loss: 2.6327 - acc: 0.1902 - val_loss: 4.1291 - val_acc: 0.1666\n",
      "\n",
      "Epoch 20/40\n",
      " - 13s - loss: 2.5721 - acc: 0.1861 - val_loss: 3.9524 - val_acc: 0.1666\n",
      "\n",
      "Epoch 21/40\n",
      " - 12s - loss: 2.5628 - acc: 0.1896 - val_loss: 3.9624 - val_acc: 0.1666\n",
      "\n",
      "Epoch 22/40\n",
      " - 12s - loss: 2.5677 - acc: 0.1892 - val_loss: 3.9535 - val_acc: 0.1666\n",
      "\n",
      "Epoch 23/40\n",
      " - 12s - loss: 2.6278 - acc: 0.1801 - val_loss: 3.9036 - val_acc: 0.1666\n",
      "\n",
      "Epoch 24/40\n",
      " - 12s - loss: 2.5238 - acc: 0.1908 - val_loss: 3.9145 - val_acc: 0.1666\n",
      "\n",
      "Epoch 25/40\n",
      " - 12s - loss: 2.4996 - acc: 0.1926 - val_loss: 3.9166 - val_acc: 0.1666\n",
      "\n",
      "Epoch 26/40\n",
      " - 12s - loss: 2.5825 - acc: 0.1863 - val_loss: 3.9462 - val_acc: 0.1666\n",
      "\n",
      "Epoch 27/40\n",
      " - 12s - loss: 2.4734 - acc: 0.1903 - val_loss: 3.7504 - val_acc: 0.1666\n",
      "\n",
      "Epoch 28/40\n",
      " - 12s - loss: 2.5949 - acc: 0.1897 - val_loss: 3.7716 - val_acc: 0.1666\n",
      "\n",
      "Epoch 29/40\n",
      " - 13s - loss: 2.6048 - acc: 0.1923 - val_loss: 3.7932 - val_acc: 0.1666\n",
      "\n",
      "Epoch 30/40\n",
      " - 12s - loss: 2.5903 - acc: 0.1828 - val_loss: 3.4069 - val_acc: 0.1666\n",
      "\n",
      "Epoch 31/40\n",
      " - 12s - loss: 2.4900 - acc: 0.1857 - val_loss: 3.3840 - val_acc: 0.1666\n",
      "\n",
      "Epoch 32/40\n",
      " - 13s - loss: 2.5632 - acc: 0.1921 - val_loss: 3.4290 - val_acc: 0.1666\n",
      "\n",
      "Epoch 33/40\n",
      " - 13s - loss: 2.5241 - acc: 0.1888 - val_loss: 2.3582 - val_acc: 0.1666\n",
      "\n",
      "Epoch 34/40\n",
      " - 13s - loss: 2.5709 - acc: 0.1829 - val_loss: 2.7730 - val_acc: 0.1805\n",
      "\n",
      "Epoch 35/40\n",
      " - 12s - loss: 2.4708 - acc: 0.1874 - val_loss: 2.4845 - val_acc: 0.1805\n",
      "\n",
      "Epoch 36/40\n",
      " - 13s - loss: 2.6356 - acc: 0.1847 - val_loss: 2.6056 - val_acc: 0.1805\n",
      "\n",
      "Epoch 37/40\n",
      " - 13s - loss: 2.4910 - acc: 0.1907 - val_loss: 2.7991 - val_acc: 0.1666\n",
      "\n",
      "Epoch 38/40\n",
      " - 12s - loss: 2.4917 - acc: 0.1903 - val_loss: 2.8069 - val_acc: 0.1666\n",
      "\n",
      "Epoch 39/40\n",
      " - 12s - loss: 2.5277 - acc: 0.1853 - val_loss: 2.8122 - val_acc: 0.1666\n",
      "\n",
      "Epoch 40/40\n",
      " - 12s - loss: 2.5080 - acc: 0.1903 - val_loss: 2.9959 - val_acc: 0.1666\n",
      "\n",
      "Train accuracy\n",
      "0.1749183895538629\n",
      "Test accuracy:\n",
      "0.166610111978283\n",
      "-------------------------------------------------------------------------------------\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_172 (TimeDi (None, None, 29, 72)      2664      \n",
      "_________________________________________________________________\n",
      "time_distributed_173 (TimeDi (None, None, 27, 32)      6944      \n",
      "_________________________________________________________________\n",
      "time_distributed_174 (TimeDi (None, None, 27, 32)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_175 (TimeDi (None, None, 3, 32)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed_176 (TimeDi (None, None, 96)          0         \n",
      "_________________________________________________________________\n",
      "lstm_34 (LSTM)               (None, 170)               181560    \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 64)                10944     \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 202,502\n",
      "Trainable params: 202,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      " 80%|████████  | 8/10 [1:07:43<16:50, 505.01s/it, best loss: -0.9436715303698676]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/temp_model.py:195: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  validation_data=(X_val_d, Y_val_d))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/40\n",
      " - 25s - loss: 0.8380 - acc: 0.6459 - val_loss: 0.5221 - val_acc: 0.8364\n",
      "\n",
      "Epoch 2/40\n",
      " - 12s - loss: 0.3874 - acc: 0.8347 - val_loss: 0.3148 - val_acc: 0.8921\n",
      "\n",
      "Epoch 3/40\n",
      " - 12s - loss: 0.2640 - acc: 0.9116 - val_loss: 0.2536 - val_acc: 0.8918\n",
      "\n",
      "Epoch 4/40\n",
      " - 12s - loss: 0.1987 - acc: 0.9255 - val_loss: 0.2415 - val_acc: 0.9247\n",
      "\n",
      "Epoch 5/40\n",
      " - 12s - loss: 0.2030 - acc: 0.9316 - val_loss: 0.2235 - val_acc: 0.9155\n",
      "\n",
      "Epoch 6/40\n",
      " - 12s - loss: 0.1845 - acc: 0.9287 - val_loss: 0.2785 - val_acc: 0.9131\n",
      "\n",
      "Epoch 7/40\n",
      " - 12s - loss: 0.1765 - acc: 0.9344 - val_loss: 0.2570 - val_acc: 0.9145\n",
      "\n",
      "Epoch 8/40\n",
      " - 12s - loss: 0.1875 - acc: 0.9304 - val_loss: 0.2710 - val_acc: 0.9209\n",
      "\n",
      "Epoch 9/40\n",
      " - 12s - loss: 0.1741 - acc: 0.9368 - val_loss: 0.2988 - val_acc: 0.9220\n",
      "\n",
      "Epoch 10/40\n",
      " - 12s - loss: 0.1601 - acc: 0.9418 - val_loss: 0.3128 - val_acc: 0.9220\n",
      "\n",
      "Epoch 11/40\n",
      " - 12s - loss: 0.1519 - acc: 0.9408 - val_loss: 0.2472 - val_acc: 0.9332\n",
      "\n",
      "Epoch 12/40\n",
      " - 12s - loss: 0.1430 - acc: 0.9446 - val_loss: 0.2551 - val_acc: 0.9196\n",
      "\n",
      "Epoch 13/40\n",
      " - 12s - loss: 0.1322 - acc: 0.9445 - val_loss: 0.2785 - val_acc: 0.9243\n",
      "\n",
      "Epoch 14/40\n",
      " - 12s - loss: 0.1422 - acc: 0.9444 - val_loss: 0.4139 - val_acc: 0.9138\n",
      "\n",
      "Epoch 15/40\n",
      " - 12s - loss: 0.1519 - acc: 0.9412 - val_loss: 0.2937 - val_acc: 0.9298\n",
      "\n",
      "Epoch 16/40\n",
      " - 12s - loss: 0.1759 - acc: 0.9427 - val_loss: 0.3063 - val_acc: 0.9264\n",
      "\n",
      "Epoch 17/40\n",
      " - 12s - loss: 0.1489 - acc: 0.9406 - val_loss: 0.4137 - val_acc: 0.9138\n",
      "\n",
      "Epoch 18/40\n",
      " - 12s - loss: 0.1381 - acc: 0.9468 - val_loss: 0.3798 - val_acc: 0.9101\n",
      "\n",
      "Epoch 19/40\n",
      " - 12s - loss: 0.1313 - acc: 0.9480 - val_loss: 0.3478 - val_acc: 0.9247\n",
      "\n",
      "Epoch 20/40\n",
      " - 13s - loss: 0.1535 - acc: 0.9449 - val_loss: 0.3587 - val_acc: 0.9264\n",
      "\n",
      "Epoch 21/40\n",
      " - 12s - loss: 0.1519 - acc: 0.9464 - val_loss: 0.3808 - val_acc: 0.9199\n",
      "\n",
      "Epoch 22/40\n",
      " - 12s - loss: 0.1243 - acc: 0.9509 - val_loss: 0.4053 - val_acc: 0.9277\n",
      "\n",
      "Epoch 23/40\n",
      " - 12s - loss: 0.1277 - acc: 0.9508 - val_loss: 0.3843 - val_acc: 0.9226\n",
      "\n",
      "Epoch 24/40\n",
      " - 12s - loss: 0.1323 - acc: 0.9510 - val_loss: 0.4493 - val_acc: 0.8799\n",
      "\n",
      "Epoch 25/40\n",
      " - 12s - loss: 0.1785 - acc: 0.9422 - val_loss: 0.4765 - val_acc: 0.9253\n",
      "\n",
      "Epoch 26/40\n",
      " - 12s - loss: 0.1391 - acc: 0.9535 - val_loss: 0.3473 - val_acc: 0.9264\n",
      "\n",
      "Epoch 27/40\n",
      " - 12s - loss: 0.1303 - acc: 0.9529 - val_loss: 0.4876 - val_acc: 0.9165\n",
      "\n",
      "Epoch 28/40\n",
      " - 12s - loss: 0.1131 - acc: 0.9596 - val_loss: 0.4654 - val_acc: 0.9050\n",
      "\n",
      "Epoch 29/40\n",
      " - 12s - loss: 0.1548 - acc: 0.9498 - val_loss: 0.4024 - val_acc: 0.9233\n",
      "\n",
      "Epoch 30/40\n",
      " - 13s - loss: 0.1177 - acc: 0.9567 - val_loss: 0.3952 - val_acc: 0.9243\n",
      "\n",
      "Epoch 31/40\n",
      " - 12s - loss: 0.1101 - acc: 0.9588 - val_loss: 0.4439 - val_acc: 0.9128\n",
      "\n",
      "Epoch 32/40\n",
      " - 12s - loss: 0.1211 - acc: 0.9589 - val_loss: 0.7482 - val_acc: 0.8850\n",
      "\n",
      "Epoch 33/40\n",
      " - 11s - loss: 0.1148 - acc: 0.9612 - val_loss: 0.5306 - val_acc: 0.9101\n",
      "\n",
      "Epoch 34/40\n",
      " - 11s - loss: 0.1134 - acc: 0.9593 - val_loss: 0.4869 - val_acc: 0.9040\n",
      "\n",
      "Epoch 35/40\n",
      " - 12s - loss: 0.1093 - acc: 0.9649 - val_loss: 0.5356 - val_acc: 0.8941\n",
      "\n",
      "Epoch 36/40\n",
      " - 12s - loss: 0.1144 - acc: 0.9588 - val_loss: 0.6785 - val_acc: 0.8931\n",
      "\n",
      "Epoch 37/40\n",
      " - 12s - loss: 0.1137 - acc: 0.9630 - val_loss: 0.5243 - val_acc: 0.9233\n",
      "\n",
      "Epoch 38/40\n",
      " - 12s - loss: 0.1125 - acc: 0.9618 - val_loss: 0.5212 - val_acc: 0.9111\n",
      "\n",
      "Epoch 39/40\n",
      " - 12s - loss: 0.1192 - acc: 0.9576 - val_loss: 0.4338 - val_acc: 0.9186\n",
      "\n",
      "Epoch 40/40\n",
      " - 12s - loss: 0.0997 - acc: 0.9657 - val_loss: 0.4532 - val_acc: 0.9145\n",
      "\n",
      "Train accuracy\n",
      "0.9661316648531012\n",
      "Test accuracy:\n",
      "0.9144893111638955\n",
      "-------------------------------------------------------------------------------------\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_177 (TimeDi (None, None, 29, 72)      2664      \n",
      "_________________________________________________________________\n",
      "time_distributed_178 (TimeDi (None, None, 27, 32)      6944      \n",
      "_________________________________________________________________\n",
      "time_distributed_179 (TimeDi (None, None, 27, 32)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_180 (TimeDi (None, None, 3, 32)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed_181 (TimeDi (None, None, 96)          0         \n",
      "_________________________________________________________________\n",
      "lstm_35 (LSTM)               (None, 170)               181560    \n",
      "_________________________________________________________________\n",
      "dropout_76 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 64)                10944     \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 202,502\n",
      "Trainable params: 202,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      " 90%|█████████ | 9/10 [1:16:03<08:23, 503.81s/it, best loss: -0.9436715303698676]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/temp_model.py:195: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  validation_data=(X_val_d, Y_val_d))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/40\n",
      " - 25s - loss: 0.9293 - acc: 0.5928 - val_loss: 1.1917 - val_acc: 0.5066\n",
      "\n",
      "Epoch 2/40\n",
      " - 12s - loss: 0.6507 - acc: 0.6907 - val_loss: 1.0210 - val_acc: 0.5684\n",
      "\n",
      "Epoch 3/40\n",
      " - 12s - loss: 0.5480 - acc: 0.7597 - val_loss: 0.6519 - val_acc: 0.6698\n",
      "\n",
      "Epoch 4/40\n",
      " - 12s - loss: 0.4667 - acc: 0.7983 - val_loss: 0.6853 - val_acc: 0.6678\n",
      "\n",
      "Epoch 5/40\n",
      " - 12s - loss: 0.4407 - acc: 0.8162 - val_loss: 0.5511 - val_acc: 0.7323\n",
      "\n",
      "Epoch 6/40\n",
      " - 12s - loss: 0.4006 - acc: 0.8445 - val_loss: 0.5048 - val_acc: 0.7693\n",
      "\n",
      "Epoch 7/40\n",
      " - 11s - loss: 0.3538 - acc: 0.8663 - val_loss: 0.4734 - val_acc: 0.7917\n",
      "\n",
      "Epoch 8/40\n",
      " - 12s - loss: 0.3524 - acc: 0.8692 - val_loss: 0.4330 - val_acc: 0.8347\n",
      "\n",
      "Epoch 9/40\n",
      " - 12s - loss: 0.3133 - acc: 0.8822 - val_loss: 0.3870 - val_acc: 0.8616\n",
      "\n",
      "Epoch 10/40\n",
      " - 12s - loss: 0.2874 - acc: 0.8962 - val_loss: 0.4210 - val_acc: 0.8578\n",
      "\n",
      "Epoch 11/40\n",
      " - 12s - loss: 0.2794 - acc: 0.8993 - val_loss: 0.3585 - val_acc: 0.8568\n",
      "\n",
      "Epoch 12/40\n",
      " - 11s - loss: 0.2674 - acc: 0.9030 - val_loss: 0.3243 - val_acc: 0.8860\n",
      "\n",
      "Epoch 13/40\n",
      " - 12s - loss: 0.2684 - acc: 0.9022 - val_loss: 0.4138 - val_acc: 0.8599\n",
      "\n",
      "Epoch 14/40\n",
      " - 12s - loss: 0.2462 - acc: 0.9078 - val_loss: 0.3868 - val_acc: 0.8714\n",
      "\n",
      "Epoch 15/40\n",
      " - 12s - loss: 0.2504 - acc: 0.9056 - val_loss: 0.3000 - val_acc: 0.8873\n",
      "\n",
      "Epoch 16/40\n",
      " - 11s - loss: 0.2362 - acc: 0.9117 - val_loss: 0.3727 - val_acc: 0.8812\n",
      "\n",
      "Epoch 17/40\n",
      " - 12s - loss: 0.2288 - acc: 0.9138 - val_loss: 0.3153 - val_acc: 0.8839\n",
      "\n",
      "Epoch 18/40\n",
      " - 12s - loss: 0.2344 - acc: 0.9149 - val_loss: 0.2812 - val_acc: 0.8992\n",
      "\n",
      "Epoch 19/40\n",
      " - 12s - loss: 0.2127 - acc: 0.9189 - val_loss: 0.3054 - val_acc: 0.8592\n",
      "\n",
      "Epoch 20/40\n",
      " - 12s - loss: 0.2108 - acc: 0.9189 - val_loss: 0.3150 - val_acc: 0.8989\n",
      "\n",
      "Epoch 21/40\n",
      " - 11s - loss: 0.2234 - acc: 0.9169 - val_loss: 0.2866 - val_acc: 0.9026\n",
      "\n",
      "Epoch 22/40\n",
      " - 12s - loss: 0.2376 - acc: 0.9162 - val_loss: 0.2795 - val_acc: 0.8965\n",
      "\n",
      "Epoch 23/40\n",
      " - 12s - loss: 0.2125 - acc: 0.9173 - val_loss: 0.2858 - val_acc: 0.9006\n",
      "\n",
      "Epoch 24/40\n",
      " - 11s - loss: 0.2012 - acc: 0.9248 - val_loss: 0.2846 - val_acc: 0.8979\n",
      "\n",
      "Epoch 25/40\n",
      " - 11s - loss: 0.2138 - acc: 0.9230 - val_loss: 0.2581 - val_acc: 0.9097\n",
      "\n",
      "Epoch 26/40\n",
      " - 11s - loss: 0.2137 - acc: 0.9242 - val_loss: 0.2871 - val_acc: 0.9165\n",
      "\n",
      "Epoch 27/40\n",
      " - 11s - loss: 0.1946 - acc: 0.9278 - val_loss: 0.2771 - val_acc: 0.9135\n",
      "\n",
      "Epoch 28/40\n",
      " - 11s - loss: 0.2014 - acc: 0.9232 - val_loss: 0.3318 - val_acc: 0.8846\n",
      "\n",
      "Epoch 29/40\n",
      " - 12s - loss: 0.1975 - acc: 0.9245 - val_loss: 0.3080 - val_acc: 0.9036\n",
      "\n",
      "Epoch 30/40\n",
      " - 12s - loss: 0.2093 - acc: 0.9240 - val_loss: 0.2864 - val_acc: 0.9070\n",
      "\n",
      "Epoch 31/40\n",
      " - 12s - loss: 0.2032 - acc: 0.9248 - val_loss: 0.3586 - val_acc: 0.8951\n",
      "\n",
      "Epoch 32/40\n",
      " - 11s - loss: 0.1954 - acc: 0.9271 - val_loss: 0.3020 - val_acc: 0.9060\n",
      "\n",
      "Epoch 33/40\n",
      " - 11s - loss: 0.2062 - acc: 0.9233 - val_loss: 0.2750 - val_acc: 0.9087\n",
      "\n",
      "Epoch 34/40\n",
      " - 12s - loss: 0.2042 - acc: 0.9229 - val_loss: 0.3046 - val_acc: 0.9060\n",
      "\n",
      "Epoch 35/40\n",
      " - 12s - loss: 0.2107 - acc: 0.9215 - val_loss: 0.2976 - val_acc: 0.9060\n",
      "\n",
      "Epoch 36/40\n",
      " - 12s - loss: 0.1794 - acc: 0.9283 - val_loss: 0.3458 - val_acc: 0.9026\n",
      "\n",
      "Epoch 37/40\n",
      " - 12s - loss: 0.1899 - acc: 0.9260 - val_loss: 0.3337 - val_acc: 0.8985\n",
      "\n",
      "Epoch 38/40\n",
      " - 12s - loss: 0.1839 - acc: 0.9261 - val_loss: 0.3471 - val_acc: 0.9067\n",
      "\n",
      "Epoch 39/40\n",
      " - 11s - loss: 0.1816 - acc: 0.9319 - val_loss: 0.3068 - val_acc: 0.9057\n",
      "\n",
      "Epoch 40/40\n",
      " - 11s - loss: 0.1761 - acc: 0.9334 - val_loss: 0.3243 - val_acc: 0.8996\n",
      "\n",
      "Train accuracy\n",
      "0.9557943416757345\n",
      "Test accuracy:\n",
      "0.8995588734306074\n",
      "-------------------------------------------------------------------------------------\n",
      "100%|██████████| 10/10 [1:24:03<00:00, 496.73s/it, best loss: -0.9436715303698676]\n"
     ]
    }
   ],
   "source": [
    "best_run, best_model ,space= optim.minimize(model=MODEL, data=data, algo=tpe.suggest, max_evals=10, trials=Trials(), notebook_name = \"/drive/My Drive/himanshukatarwar11@gmail.com_Assigment23\",return_space=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5524,
     "status": "ok",
     "timestamp": 1584267337919,
     "user": {
      "displayName": "Himanshu Katarwar",
      "photoUrl": "",
      "userId": "18404176375943820148"
     },
     "user_tz": -330
    },
    "id": "ulwO4gdQ57xP",
    "outputId": "f53654ba-a833-4b15-a729-bb1e344e598f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:59: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:44: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 1s 284us/step\n",
      "---------------------\n",
      "|      Accuracy      |\n",
      "---------------------\n",
      "94.37%\n",
      "\n",
      "----------------------------------\n",
      "|      Best Hyper-Parameters      |\n",
      "----------------------------------\n",
      "{'Dropout': 0.3257301479402539, 'Dropout_1': 0.8176968367924008, 'l2': 4.3460722016022965e-07, 'l2_1': 6.975105778097833e-06, 'l2_2': 5.157655840964875e-07, 'l2_3': 4.2580338825158776e-07, 'lr': 0.0014310905039904911, 'pool_size': 4}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_d, Y_train_d, X_val_d,  Y_val_d = data()\n",
    "score = best_model.evaluate(X_val_d, Y_val_d)\n",
    "\n",
    "print('---------------------')\n",
    "print('|      Accuracy      |')\n",
    "print('---------------------')\n",
    "acc = np.round((score[1]*100), 2)\n",
    "print(str(acc)+\"%\\n\")\n",
    "    \n",
    "print('----------------------------------')\n",
    "print('|      Best Hyper-Parameters      |')\n",
    "print('----------------------------------')\n",
    "print(best_run)\n",
    "print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W-j0hGC7m1M-"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#https://github.com/UdiBhaskar/Human-Activity-Recognition--Using-Deep-NN\n",
    "def plot_confusion_matrix(cm, classes,normalize=False,title='Confusion matrix',cmap=plt.cm.Blues):\n",
    "  if normalize:\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "  plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "  plt.title(title)\n",
    "  plt.colorbar()\n",
    "  tick_marks = np.arange(len(classes))\n",
    "  plt.xticks(tick_marks, classes, rotation=90)\n",
    "  plt.yticks(tick_marks, classes)\n",
    "  fmt = '.2f' if normalize else 'd'\n",
    "  thresh = cm.max() / 2.\n",
    "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, format(cm[i, j], fmt),horizontalalignment=\"center\",color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "  plt.tight_layout()\n",
    "  plt.ylabel('True label')\n",
    "  plt.xlabel('Predicted label')\n",
    "\n",
    "def confusion_matrix_cnn(Y_true, Y_pred):\n",
    "  Y_true = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_true, axis=1)])\n",
    "  Y_pred = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_pred, axis=1)])\n",
    "  #return pd.crosstab(Y_true, Y_pred, rownames=['True'], colnames=['Pred'])\n",
    "  return metrics.confusion_matrix(Y_true, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 663
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2399,
     "status": "ok",
     "timestamp": 1584268015476,
     "user": {
      "displayName": "Himanshu Katarwar",
      "photoUrl": "",
      "userId": "18404176375943820148"
     },
     "user_tz": -330
    },
    "id": "esxlSsd7AUse",
    "outputId": "1a2362d3-7499-4ee5-f7e7-e8d2329666ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "|      Accuracy      |\n",
      "---------------------\n",
      "94.37%\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjQAAAIxCAYAAABaRiKwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuff/Abrg2aIlqaIpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('---------------------')\n",
    "print('|      Accuracy      |')\n",
    "print('---------------------')\n",
    "acc = np.round((score[1]*100), 2)\n",
    "print(str(acc)+\"%\\n\")\n",
    "plt.figure(figsize=(8,8))\n",
    "cm = confusion_matrix_cnn(Y_val_d, best_model.predict(X_val_d))\n",
    "plot_confusion_matrix(cm, classes=['WALKING','WALKING_UPSTAIRS','WALKING_DOWNSTAIRS','SITTING','STANDING','LAYING'], normalize=True, title='Normalized confusion matrix', cmap = plt.cm.Greens)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cKBbzUdcuQoM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "himanshukatarwar11@gmail.com_Assigment23.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
